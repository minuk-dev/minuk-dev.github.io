{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5561f7",
   "metadata": {},
   "source": [
    "\n",
    "# 3주차\n",
    "\n",
    "## Posterior Predictive Distribution\n",
    "\n",
    "* After the data $y$ have been observed, we can predict an unknown observable $\\tilde y$\n",
    "* The posterior predictive distribution of a future observation, $\\tilde y$ is:\n",
    "  $$ \\begin{aligned} p(\\tilde y \\vert y) &= \\int p(\\tilde y, \\theta \\vert y) d\\theta \\\\ &= \\int p(\\tilde y \\vert \\theta, y) p(\\theta \\vert y ) d \\theta \\\\ &= \\int p(\\tilde \\vert \\theta) p(\\theta \\vert y) d \\theta \\end{aligned}$$\n",
    "* Assumed $y$ and $\\tilde y$ are conditional independent given $\\theta$\n",
    "\n",
    "* prior predictive distribution before $y$ observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f32a0",
   "metadata": {},
   "source": [
    "### Example 1 : Binomial model\n",
    "   $$ y_i \\overset{iid}{\\sim} Bern(\\theta) $$\n",
    "   $$ Y \\sim Bin(n, \\theta), 0 \\le \\theta \\le 1$$\n",
    "   $$ \\begin{aligned} \\theta &\\sim Unif(0, 1) \\\\ &\\Rightarrow \\theta \\vert y \\sim Beta(y + 1, n - y + 1) \\end{aligned}$$\n",
    " * Posterior predictive distribution for $\\tilde y = 1$\n",
    "   $$ P(\\tilde y  =1 \\vert y) = \\frac{y + 1}{n + 2}$$\n",
    "   which is known as `Laplace's law of succession`.\n",
    " \n",
    " $$ \\begin{aligned} p(\\tilde y = 1 \\vert y) = \\int_0^1 p(\\tilde y = 1 \\vert \\theta) p(\\theta \\vert y) d \\theta = \\int_0^1 \\theta p(\\theta \\vert y) d \\theta = E[\\theta \\vert y] = \\frac{y + 1}{n + 2} \\end{aligned}$$\n",
    " $$ y = 0 \\text{ (all failures) } \\Rightarrow p(\\tilde y = 1 \\vert y) = \\frac{1}{n + 2}$$\n",
    " $$ y = 1 \\text{ (all successes) } \\Rightarrow p(\\tilde y = 1 \\vert y) = \\frac{n + 1}{n + 2}$$\n",
    "\n",
    " * prior predictive distribution\n",
    "   $$p(\\tilde y = 1) = \\int_0^1 p(\\tilde y = 1 \\vert \\theta) p(\\theta) d \\theta = \\int_0^1 \\theta d \\theta = \\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b573ff6",
   "metadata": {},
   "source": [
    "### Example 2 : Poisson Model\n",
    " * Data model: $y_i \\overset{iid}{\\sim} Poisson(\\theta), i= 1, ..., n$\n",
    " * Prior distribution : $\\theta \\sim Gamma(\\alpha, \\beta)$\n",
    " * Posterior distribution of $\\theta$ given $y$\n",
    " $$ L(\\theta) = \\prod_{i=1}^n \\frac{1}{y_i !} \\theta^{y_i} e ^{- \\theta} = (\\prod_{i=1}^n \\frac{1}{y_i !} \\theta^{\\sum y_i} e ^{-n \\theta}$$\n",
    " * MLE for $\\theta$:\n",
    "   $$ log L(\\theta) = log(\\prod \\frac{1}{y_i!} + \\sum y_i log \\theta - n \\theta$$\n",
    "   $$ \\begin{aligned} \\frac{\\partial log L}{\\partial \\theta} = \\frac{\\sum y_i}{\\theta} - n = 0 \\\\ \\Rightarrow \\hat \\theta_{ML} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar y \\end{aligned}$$\n",
    "   \n",
    " * Posterior Distribution\n",
    "   $$\\begin{aligned} p(\\theta \\vert y) &\\propto p(y \\vert \\theta) p(\\theta) \n",
    "   \\\\ &= [\\prod_{i=1}^n \\frac{1}{y_i !} \\theta^{y_i} e^{- \\theta}] \\frac{1}{\\Gamma(\\alpha) \\beta^{\\alpha}} \\theta^{\\alpha - 1} e ^{- \\frac{\\theta}{\\beta}} \n",
    "   \\\\ &\\propto \\theta^{\\sum y_i e ^{- n\\theta}} e ^{\\alpha - 1} e^{- \\frac{\\theta}{\\beta}} \n",
    "   \\\\ &= e^{\\sum y_i + \\alpha - 1} e ^{-(n + \\frac{1}{\\beta}) \\theta} \\end{aligned}$$\n",
    "   $$ \\begin{aligned}\\int_0^{\\infty} c \\theta^{\\sum y_i + \\alpha - 1} e^{-(n + \\frac{1}{\\beta})\\theta} d \\theta = 1 \n",
    "   \\\\ \\Rightarrow \\theta \\vert y \\sim Gamma(\\sum y_i + \\alpha, [n + \\frac{1}{\\beta}]^{-1}) \n",
    "   \\\\ \\Rightarrow p(\\theta \\vert y) = \\frac{(n + \\frac{1}{\\beta})^{\\sum y_i + \\alpha}}{\\Gamma(\\sum y_i + \\alpha)} e^{\\sum y_i + \\alpha - 1} e ^{-(n + \\frac{1}{\\beta}) \\theta} \\end{aligned}$$\n",
    "   $$ \\begin{aligned}E[\\theta \\vert y] &= \\frac{\\sum y_i + \\alpha}{n + \\frac{1}{\\beta}} = \\hat \\theta_{Bayes} \n",
    "   \\\\ &= \\frac{n}{n+\\frac{1}{\\beta}} (\\frac{\\sum y_i}{n}) + \\frac{\\frac{1}{\\beta}}{n + \\frac{1}{\\beta}} (\\alpha \\beta) \n",
    "   \\\\ &\\Rightarrow \\text{ Weighted average of sample mean and prior mean} \\end{aligned}$$\n",
    "     * $n \\uparrow \\Rightarrow E[\\theta \\vert y] \\rightarrow \\hat \\theta_{ML}$\n",
    "     * $n \\downarrow \\Rightarrow E[\\theta \\vert y] \\rightarrow \\alpha \\beta \\text{ (prior mean) }$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed25adb",
   "metadata": {},
   "source": [
    "## Posterior Predictive Distribution of Poisson Model\n",
    " * Posterior predictive distribution, $p(\\tilde y \\vert y)$:\n",
    "   $$ \\begin{aligned}p(\\tilde y \\vert y_1, ..., y_n) &= \\int_0^{\\infty} p(\\tilde y \\vert \\theta) p(\\theta \\vert y_1, ..., y_n) d \\theta \n",
    "   \\\\ &= \\int_0^{\\infty} \\frac{1}{\\tilde y !} e^{- \\theta} \\theta^{\\tilde y} \\frac{(n + \\frac{1}{\\beta})^{\\sum y_i + \\alpha}}{\\Gamma(\\sum y_i + \\alpha)} \\theta^{\\sum y_i + \\alpha - 1} e ^{-(n + \\frac{1}{\\beta}) \\theta} d \\theta \n",
    "   \\\\ &= [\\frac{1}{\\tilde y!} \\frac{(n + \\frac{1}{\\beta})^{\\sum y_i + \\alpha}}{\\Gamma(\\sum y_i + \\alpha)}] \\int_0^{\\infty} \\theta^{\\tilde y + \\sum y_i + \\alpha - 1} e^{-(n + \\frac{1}{\\beta} + 1) \\theta} d\\theta \n",
    "   \\\\ &= [\\frac{1}{\\tilde y !} \\frac{(n + \\frac{1}{\\beta})^{\\sum y_i + \\alpha}}{\\Gamma(\\sum y_i + \\alpha)}] [\\frac{\\Gamma(\\tilde y + \\sum y_i + \\alpha)}{(n + \\frac{1}{\\beta} + 1)^{\\tilde y + \\sum y_i + \\alpha}}] \n",
    "   \\\\ &= \\frac{\\Gamma(\\tilde y + \\sum y_i + \\alpha)}{\\Gamma(\\sum y_i + \\alpha) \\tilde y!} (\\frac{n + \\frac{1}{\\beta}}{n + \\frac{1}{\\beta} + 1})^{\\sum y_i + \\alpha} (\\frac{1}{n + \\frac{1}{\\beta} + 1})^{\\tilde y} \n",
    "   \\\\ \\Rightarrow \\theta \\vert y \\sim NegBin(\\sum y_i + \\alpha, \\frac{n + \\frac{1}{\\beta}}{n + \\frac{1}{\\beta} + 1})\n",
    "   \\\\ \\tilde y = \\text{ the number failures until r th successes}\n",
    "   \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c89922",
   "metadata": {},
   "source": [
    "## Normal Model with a Single Observation\n",
    " * Normal model with unknown mena $\\theta$ and known variance $\\sigma^2$\n",
    "   $$ y \\sim N(\\theta, \\sigma^2)$$\n",
    " * Prior distribution : $\\theta \\sim N(\\mu : \\tau^2)$\n",
    " * Posterior distribution of $\\theta$ given $y$\n",
    "   $$\\begin{aligned}p(\\theta \\vert y) &\\propto p(y \\vert \\theta) p(\\theta) \n",
    "   \\\\ &= [\\frac{1}{\\sqrt{2 \\pi} \\sigma} e ^{- \\frac{1}{2 \\sigma^2}(y - \\theta)^2}] [ \\frac{1}{\\sqrt{2 \\pi} \\tau} e ^{- \\frac{1}{2 \\tau^2} (\\theta - \\mu)^2}]\n",
    "   \\\\ &\\propto exp[-\\frac{1}{2 \\sigma^2}(y ^2 - 2 y \\theta + \\theta^2) - \\frac{1}{2 \\tau^2} (\\theta^2 - 2 \\theta \\mu + \\mu^2)]\n",
    "   \\\\ &\\propto exp[- \\frac{1}{2 \\sigma^2}(\\theta^2 - 2 y \\theta) - \\frac{1}{2 \\tau^2}(\\theta - 2 \\mu \\theta)]\n",
    "   \\\\ &= exp[ - \\frac{1}{2} (\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}) \\theta^2 + 2 \\frac{1}{2}  (\\frac{1}{\\sigma^2} + \\frac{\\mu}{\\tau^2}) \\theta]\n",
    "   \\\\ &= exp[ - \\frac{1}{2} (\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}) (\\theta^2 - 2 \\frac{\\frac{y}{\\sigma^2} + \\frac{\\mu}{\\tau^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}} \\theta)]\n",
    "   \\\\ &\\propto exp[- \\frac{1}{2} (\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2})(\\theta - \\frac{\\frac{y}{\\sigma^2} + \\frac{\\mu}{\\tau^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}})^2]\n",
    "   \\\\ \\theta \\vert y \\sim N( \\frac{\\frac{y}{\\sigma^2} + \\frac{\\mu}{\\tau^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}}, [\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}]^{-1})\n",
    "   \\end{aligned}$$\n",
    "   $$ E[\\theta \\vert y] = \\frac{\\frac{1}{\\sigma^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}} y + \\frac{\\frac{1}{\\tau^2}}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}} \\mu $$\n",
    "   * $\\tau^2$ means prior variance\n",
    "   * If $\\tau^2 \\uparrow \\Rightarrow \\text{ Little information } \\Rightarrow E[\\theta \\vert y] \\rightarrow y \\text{ (sample mean) }$\n",
    "   * If $\\tau^2 \\downarrow \\Rightarrow \\text{ Much information } \\Rightarrow E[\\theta \\vert y] \\rightarrow \\mu$\n",
    "   \n",
    "* posterior variance = $[\\frac{1}{\\sigma^2} + \\frac{1}{\\tau^2}]^{-1}$\n",
    "* $\\text{precision} = \\frac{1}{\\text{variance}}$ (reciprocal of variance)\n",
    "* $\\frac{1}{\\sigma^2}$ : precision of data model\n",
    "* $\\frac{1}{\\tau ^2}$ : precision of prior\n",
    "* posterior precision = prior precision + data precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54028e6b",
   "metadata": {},
   "source": [
    "## Normal Model with Multiple Observations\n",
    " * Normal model with unknown mean $\\theta$ and known variance $\\sigma^2$\n",
    "   $$y_i \\overset{iid}{\\sim} N(\\theta, \\sigma^2), i =1,...,n$$\n",
    " * Prior distribution : $\\theta \\sim N(\\mu, \\tau^2)$\n",
    " * Posterior distribution of $\\theta$ given $y_1, ..., y_n$\n",
    "   $$\\begin{aligned}p(\\theta \\vert y) \\propto p(y \\vert \\theta) p(\\theta)\n",
    "   \\\\ &\\propto [\\prod_{i=1}^n e ^{- \\frac{1}{2 \\sigma^2} (y_i - \\theta)^2}] e^{- \\frac{1}{2 \\tau^2} (\\theta - \\mu)^2 } \n",
    "   \\\\ &= e^{- \\frac{1}{2 \\sigma^2} \\sum_{i=1}^n (y_i - \\theta)^2} e ^{- \\frac{1}{2 \\tau^2} (\\theta - \\mu)^2}\n",
    "   \\\\ &\\propto exp[-\\frac{1}{2} (\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}) (\\theta - \\frac{\\frac{\\sum y_i}{\\sigma} + \\frac{\\mu}{\\tau^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}})^2]\n",
    "   \\\\ \\Rightarrow \\theta \\vert y \\sim N (\\frac{\\frac{\\sum y_i}{\\sigma^2} + \\frac{\\mu}{\\tau^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}}, [\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}]^{-1})\n",
    "   \\end{aligned}$$\n",
    "   \n",
    " * Posterior mean\n",
    "   $$E[\\theta \\vert y] = \\frac{\\frac{n}{\\sigma^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}} (\\frac{\\sum y_i}{n}) + \\frac{\\frac{1}{\\tau^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}}(\\mu)$$\n",
    "   $$ n \\uparrow \\Rightarrow E[\\theta \\vert] y \\rightarrow \\hat \\theta_{ML} = \\bar y$$\n",
    "   $$ \\tau^2 \\uparrow \\text{(no information)} \\Rightarrow E[\\theta \\vert y] \\rightarrow \\bar y$$\n",
    "   $$ \\tau^2 \\downarrow \\text{(much information)} \\Rightarrow E[\\theta \\vert y] \\rightarrow \\mu$$\n",
    "   * Posterior precision = sample precision + prior precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a032062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
