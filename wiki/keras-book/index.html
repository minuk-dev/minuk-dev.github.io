<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>케라스 창시자에게 배우는 딥러닝 책 공부</title><style>html body{font-family:raleway,sans-serif;background-color:#fff}:root{--accent:#00a3d2;--border-width:5px}</style><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Raleway"><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css integrity=sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN crossorigin=anonymous><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/copy-btn.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script src=/js/copy-btn.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script>$(document).on("click",function(){$(".collapse").collapse("hide")})</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-98056974-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-98056974-1")</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=google-site-verification content="g_3tJyj-KkW-_wKx7Ij5GimHV1nKPZXetCz8ydbBAfA"></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><a class="navbar-brand visible-xs" href=#>케라스 창시자에게 배우는 딥러닝 책 공부
</a><button class=navbar-toggle data-target=.navbar-collapse data-toggle=collapse>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="collapse navbar-collapse"><ul class="nav navbar-nav"><li><a href=/>Home</a></li><li><a href=/wiki/>Wiki</a></li><li><a href=/posts/>Posts</a></li><li><a href=/about/>About</a></li></ul></div></div></nav><main><div class=navigator style=display:flex><div style=display:flex><div class=parent-doc style=flex:none><button class="btn btn-link" onclick='(function(e){e.querySelector("a").click()})(this)'>
<i class="fa fa-arrow-left"></i>
[[Book Review]]</button></div></div></div><div><h2>케라스 창시자에게 배우는 딥러닝 책 공부</h2><a href=https://github.com/minuk-dev/minuk-dev.github.io/blame/master/content/wiki/keras-book.md><h5>created : Sun, 22 Aug 2021 16:04:33 +0900</h5><h5>modified : Sun, 22 Aug 2021 23:23:45 +0900</h5></a><a href=https://minuk.dev/tags/keras><kbd class=item-tag>keras</kbd></a></div><aside class=navbar id=nav-toc style=text-align:left><nav id=TableOfContents><ul><li><a href=#1-딥러닝이란-무엇인가>1. 딥러닝이란 무엇인가?</a><ul><li><a href=#11-인공지능과-머신러닝-딥러닝>1.1 인공지능과 머신러닝, 딥러닝</a></li><li><a href=#12-딥러닝-이전-머신러닝의-간략한-역사>1.2 딥러닝 이전: 머신러닝의 간략한 역사</a></li><li><a href=#13-왜-딥러닝일까-왜-지금일까>1.3 왜 딥러닝일까? 왜 지금일까?</a></li></ul></li><li><a href=#2-신경망의-수학적-구성요소>2. 신경망의 수학적 구성요소</a><ul><li><a href=#22-신경망을-위한-데이터-표현>2.2 신경망을 위한 데이터 표현</a></li><li><a href=#신경망의-엔진-그레디언트-기반-최적화>신경망의 엔진: 그레디언트 기반 최적화</a></li><li><a href=#요약>요약</a></li></ul></li><li><a href=#3장-신경망-시작하기>3장 신경망 시작하기</a><ul><li><a href=#31-신경망의-구조>3.1 신경망의 구조</a></li><li><a href=#32-케라스-소개>3.2 케라스 소개</a></li><li><a href=#33-딥러닝-컴퓨터-셋팅>3.3 딥러닝 컴퓨터 셋팅</a></li><li><a href=#34-영화-리뷰-분류-이진-분류-예제>3.4 영화 리뷰 분류: 이진 분류 예제</a></li><li><a href=#정리>정리</a></li><li><a href=#35-뉴스기사-분류-다중-분류-문제>3.5 뉴스기사 분류: 다중 분류 문제</a></li><li><a href=#정리-1>정리</a></li><li><a href=#36-주택-가격-예측-회귀-문제>3.6 주택 가격 예측: 회귀 문제</a></li></ul></li></ul></nav></aside><div align=start class=content data-spy=scroll data-offset=20 data-target=#nav-toc style=position:relative><h2 id=1-딥러닝이란-무엇인가>1. 딥러닝이란 무엇인가?</h2><h3 id=11-인공지능과-머신러닝-딥러닝>1.1 인공지능과 머신러닝, 딥러닝</h3><h3 id=12-딥러닝-이전-머신러닝의-간략한-역사>1.2 딥러닝 이전: 머신러닝의 간략한 역사</h3><ul><li>확률적 모델링</li><li>초창기 신경망</li><li>서포트 벡터 머신</li><li>결정 트리, 랜덤 포레스트, 그래디언트 부스팅 머신</li><li>신경망</li><li>최근 동향 : 그래디언트 부스팅(구조적인 데이터), 딥러닝 (이미지 데이터)</li></ul><h3 id=13-왜-딥러닝일까-왜-지금일까>1.3 왜 딥러닝일까? 왜 지금일까?</h3><ul><li>하드웨어 발전</li><li>활성화 함수 : ReLU</li><li>가중치 초기화 방법 : Xavier 초기화 Glorot 초기화</li><li>최적화 방법 : RMSProp, Adam</li></ul><h2 id=2-신경망의-수학적-구성요소>2. 신경망의 수학적 구성요소</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> keras.datasets <span style=color:#f92672>import</span> mnist
</span></span><span style=display:flex><span>(train_images, train_labels), (test_imagese, test_labels) <span style=color:#f92672>=</span> mnist<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>network <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>Sequential()
</span></span><span style=display:flex><span>network<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>512</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>,)))
</span></span><span style=display:flex><span>network<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>10</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;softmax&#39;</span>))
</span></span><span style=display:flex><span>network<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rmsprop&#39;</span>,
</span></span><span style=display:flex><span>                loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;categorical_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>                metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>reshape((train_images<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>train_images <span style=color:#f92672>=</span> train_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>test_images <span style=color:#f92672>=</span> test_images<span style=color:#f92672>.</span>reshape((test_images<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], <span style=color:#ae81ff>28</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>28</span>))
</span></span><span style=display:flex><span>test_images <span style=color:#f92672>=</span> test_images<span style=color:#f92672>.</span>astype(<span style=color:#e6db74>&#39;float32&#39;</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras.utils <span style=color:#f92672>import</span> to_categorical
</span></span><span style=display:flex><span>train_labels <span style=color:#f92672>=</span> to_categorical(train_labels)
</span></span><span style=display:flex><span>test_labels <span style=color:#f92672>=</span> to_categorical(test_labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>network<span style=color:#f92672>.</span>fit(train_images, train_labels, ephocs<span style=color:#f92672>=</span><span style=color:#ae81ff>5</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>)
</span></span><span style=display:flex><span>test_loss, test_acc <span style=color:#f92672>=</span> network<span style=color:#f92672>.</span>evaluate(test_images, test_labels)
</span></span><span style=display:flex><span>print(<span style=color:#e6db74>&#39;test_acc:&#39;</span>, test_acc)
</span></span></code></pre></div><h3 id=22-신경망을-위한-데이터-표현>2.2 신경망을 위한 데이터 표현</h3><ul><li>스칼라(0D 텐서)</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(<span style=color:#ae81ff>12</span>)
</span></span></code></pre></div><ul><li>벡터(1D 텐서)</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([<span style=color:#ae81ff>12</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>14</span>, <span style=color:#ae81ff>7</span>])
</span></span></code></pre></div><ul><li>행렬(2D 텐서)</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>x <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>5</span>, <span style=color:#ae81ff>78</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>34</span>, <span style=color:#ae81ff>0</span>],
</span></span><span style=display:flex><span>              [<span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>79</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>35</span>, <span style=color:#ae81ff>1</span>],
</span></span><span style=display:flex><span>              [<span style=color:#ae81ff>7</span>, <span style=color:#ae81ff>80</span>, <span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>36</span>, <span style=color:#ae81ff>2</span>]])
</span></span></code></pre></div><ul><li><p>핵심속성:</p><ul><li>축의 개수(랭크) : ndim</li><li>크기(shape)</li><li>데이터 타입(dtype)</li></ul></li><li><p>이미지 출력</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>digit <span style=color:#f92672>=</span> train_images[<span style=color:#ae81ff>4</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>imshow(digit, cmap<span style=color:#f92672>=</span>plt<span style=color:#f92672>.</span>cm<span style=color:#f92672>.</span>binary)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><ul><li><p>텐서의 실제 사례:</p><ul><li>벡터 데이터 : (sample, features) 크기의 2D 텐서</li><li>시계열 데이터 또는 시퀀스(sequence) 데이터 : (samples, timesteps, features)</li><li>이미지 : (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서</li><li>동영상 : (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서</li></ul></li><li><p>브로드캐스팅:</p><ul><li>큰 텐서의 ndim에 맞도록 작은 텐서에 (브로드캐스팅 축이라고 부르는) 축이 추가된다.</li><li>작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다.</li></ul></li></ul><h3 id=신경망의-엔진-그레디언트-기반-최적화>신경망의 엔진: 그레디언트 기반 최적화</h3><ul><li>텐서 연산의 변화율: 그레디언트</li><li>확률적 경사 하강법</li><li>변화율 연결: 역전파 알고리즘</li></ul><h3 id=요약>요약</h3><ul><li>학습은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화하는 모델 파라미터의 조합을 찾는 것을 의미한다.</li><li>데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행된다. 네트워크의 파라메터는 그래디언터의 반대방향으로 조금씩(학습률에 의해 정의도니 크기만큼) 움직인다.</li><li>전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 때문에 가능하다. 현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해 주는 그래디언트 함수를 구성하기 위해 미분의 연쇄 법칙을 사용한다.</li><li>손실과 옵티마이저</li><li>손실은 훈련하는 동안 최소화해야 할 양이므로 해결하려눈 문제의 성공을 측정하는데 사용한다.</li><li>옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의한다.</li></ul><h2 id=3장-신경망-시작하기>3장 신경망 시작하기</h2><h3 id=31-신경망의-구조>3.1 신경망의 구조</h3><ul><li>네트워크(또는 모델)를 구성하는 층</li><li>입력 데이터와 그에 상응하는 타깃</li><li>학습에 사용할 피드백 신호를 정의하는 손실 함수</li><li>학습 진행방식을 결정하는 옵티마이저</li></ul><h3 id=32-케라스-소개>3.2 케라스 소개</h3><h3 id=33-딥러닝-컴퓨터-셋팅>3.3 딥러닝 컴퓨터 셋팅</h3><h3 id=34-영화-리뷰-분류-이진-분류-예제>3.4 영화 리뷰 분류: 이진 분류 예제</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> keras.datasets <span style=color:#f92672>import</span> imdb
</span></span><span style=display:flex><span>(train_data, train_labels), (test_data, test_labels) <span style=color:#f92672>=</span> imdb<span style=color:#f92672>.</span>load_data(num_words<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>vectorize_sequences</span>(sequences, dimension<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>):
</span></span><span style=display:flex><span>  results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((len(sequences), dimension))
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> i, sequence <span style=color:#f92672>in</span> enumerate(sequences):
</span></span><span style=display:flex><span>    results[i, sequence] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> results
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> vectorize_sequences(train_data)
</span></span><span style=display:flex><span>x_test <span style=color:#f92672>=</span> vectorize_sequences(test_data)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>Sequential()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>16</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10000</span>,)))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>16</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>1</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;sigmoid&#39;</span>))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rmsprop&#39;</span>,
</span></span><span style=display:flex><span>              loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>              metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span><span style=color:#75715e># from keras import optimizers</span>
</span></span><span style=display:flex><span><span style=color:#75715e># model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_val <span style=color:#f92672>=</span> x_train[:<span style=color:#ae81ff>10000</span>]
</span></span><span style=display:flex><span>partial_x_train <span style=color:#f92672>=</span> x_train[<span style=color:#ae81ff>10000</span>:]
</span></span><span style=display:flex><span>y_val <span style=color:#f92672>=</span> y_train[:<span style=color:#ae81ff>10000</span>]
</span></span><span style=display:flex><span>partial_y_train[<span style=color:#ae81ff>10000</span>;]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(partial_x_train, partial_y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, validation_data<span style=color:#f92672>=</span>(x_val, y_val))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 훈련 검증 손실 그리기</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_dict <span style=color:#f92672>=</span> history<span style=color:#f92672>.</span>history
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;loss&#39;</span>]
</span></span><span style=display:flex><span>val_loss <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;val_loss&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> range(<span style=color:#ae81ff>1</span>, len(loss) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, loss, <span style=color:#e6db74>&#39;bo&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Training loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_loss, <span style=color:#e6db74>&#39;b&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Training and validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Epochs&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 훈련 검증 정확도 그리기</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>clf()
</span></span><span style=display:flex><span>acc <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;acc&#39;</span>]
</span></span><span style=display:flex><span>val_acc <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;val_acc&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, acc, <span style=color:#e6db74>&#39;bo&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Training acc&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_acc, <span style=color:#e6db74>&#39;b&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Validation acc&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Training and validation accuracy&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Epochs&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Accuracy&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>predict(x_test)
</span></span></code></pre></div><h3 id=정리>정리</h3><ul><li>원본 데이터를 신경망에 텐서로 주입하기 위해서 많은 전처리가 필요하다.</li><li>relu 활성화 함수</li><li>이진 분류 문제에서 하나의 유닛과 sigmoid 활성화 함수를 가진 Dense 층으로 끝나야 한다.</li><li>이진 분류 문제에서 이런 손실함수는 binary_crossentropy 이다.</li><li>rmsprop는 일반적으로 좋은 선택이다.</li><li>훈련 데이터에서 과적합을 유의해야 한다.</li></ul><h3 id=35-뉴스기사-분류-다중-분류-문제>3.5 뉴스기사 분류: 다중 분류 문제</h3><ul><li>로이터 데이터셋</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> keras.datasets <span style=color:#f92672>import</span> reuters
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(train_data, train_labels), (test_data, test_labels) <span style=color:#f92672>=</span> reuters<span style=color:#f92672>.</span>load_data(num_wors<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>)
</span></span><span style=display:flex><span>word_index <span style=color:#f92672>=</span> reuters<span style=color:#f92672>.</span>get_word_index()
</span></span><span style=display:flex><span>reverse_word_index <span style=color:#f92672>=</span> dict([(value, key) <span style=color:#66d9ef>for</span> (key, value) <span style=color:#f92672>in</span> word_index<span style=color:#f92672>.</span>items()])
</span></span><span style=display:flex><span>decoded_newswire <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39; &#39;</span><span style=color:#f92672>.</span>join([reverse_word_index<span style=color:#f92672>.</span>get(i <span style=color:#f92672>-</span> <span style=color:#ae81ff>3</span>, <span style=color:#e6db74>&#39;?&#39;</span>) <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> train_data[<span style=color:#ae81ff>0</span>]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>vectorize_sequences</span>(sequences, dimension<span style=color:#f92672>=</span><span style=color:#ae81ff>10000</span>):
</span></span><span style=display:flex><span>  results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((len(sequences), dimension))
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> i, sequence <span style=color:#f92672>in</span> enumerate(sequences):
</span></span><span style=display:flex><span>    results[i, sequence] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> results
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_train <span style=color:#f92672>=</span> vectorize_sequences(train_data)
</span></span><span style=display:flex><span>x_test <span style=color:#f92672>=</span> vectorize_sequences(test_data)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>to_one_hot</span>(labels, dimension<span style=color:#f92672>=</span><span style=color:#ae81ff>46</span>):
</span></span><span style=display:flex><span>  results <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>zeros((len(labels), dimension))
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>for</span> i, label <span style=color:#f92672>in</span> enumerate(labels):
</span></span><span style=display:flex><span>    results[i, label] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> results
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>one_hot_train_labels <span style=color:#f92672>=</span> to_one_hot(train_labels)
</span></span><span style=display:flex><span>one_hot_test_labels <span style=color:#f92672>=</span> to_one_hot(test_labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras.utils.np_utils <span style=color:#f92672>import</span> to_categorical
</span></span><span style=display:flex><span>one_hot_train_label <span style=color:#f92672>=</span> to_categorical(train_labels)
</span></span><span style=display:flex><span>one_hot_test_labels <span style=color:#f92672>=</span> to_categorical(test_labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>Sequential()
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10000</span>,)))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>46</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;softmax&#39;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rmsprop&#39;</span>,
</span></span><span style=display:flex><span>              loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;categorical_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>              metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_val <span style=color:#f92672>=</span> x_train[:<span style=color:#ae81ff>1000</span>]
</span></span><span style=display:flex><span>partial_x_train <span style=color:#f92672>=</span> x_train[<span style=color:#ae81ff>1000</span>:]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>y_val <span style=color:#f92672>=</span> y_train[:<span style=color:#ae81ff>1000</span>]
</span></span><span style=display:flex><span>partial_y_train <span style=color:#f92672>=</span> y_train[<span style=color:#ae81ff>1000</span>:]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>fit(partial_x_train, partial_y_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>,
</span></span><span style=display:flex><span>                    validation_data<span style=color:#f92672>=</span>(x_val, y_val))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 훈련 검증 손실 그리기</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>history_dict <span style=color:#f92672>=</span> history<span style=color:#f92672>.</span>history
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;loss&#39;</span>]
</span></span><span style=display:flex><span>val_loss <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;val_loss&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>epochs <span style=color:#f92672>=</span> range(<span style=color:#ae81ff>1</span>, len(loss) <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, loss, <span style=color:#e6db74>&#39;bo&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Training loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_loss, <span style=color:#e6db74>&#39;b&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Training and validation loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Epochs&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Loss&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 훈련 검증 정확도 그리기</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>clf()
</span></span><span style=display:flex><span>acc <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;acc&#39;</span>]
</span></span><span style=display:flex><span>val_acc <span style=color:#f92672>=</span> history_dict[<span style=color:#e6db74>&#39;val_acc&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, acc, <span style=color:#e6db74>&#39;bo&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Training acc&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>plot(epochs, val_acc, <span style=color:#e6db74>&#39;b&#39;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Validation acc&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Training and validation accuracy&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Epochs&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Accuracy&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>legend()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>show()
</span></span></code></pre></div><h3 id=정리-1>정리</h3><ul><li>N 개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 Dense 층의 크기는 N이여야 한다.</li><li>단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 softmax 활성화 함수를 사용해야한다.</li><li>이런 문제에서는 항상 범주형 크로스엔트로피를 사용해야 한다.</li><li>다중 분류에서 레이블을 다루는 두 가지 방법이 있다.:<ul><li>레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 ㅊategorical_crossentropy로 손실함수를 사용한다.</li><li>레이블을 정수로 인코딩하고 sparse_categorical_crossentropy 손실 함수를 사용한다.</li></ul></li><li>많은 수의 범주를 분류할 때 중간층의 크기가 너무 ㅏㅈㄱ아 네트워크에 정보의 병목이 생기지 않도록 해야한다.</li></ul><h3 id=36-주택-가격-예측-회귀-문제>3.6 주택 가격 예측: 회귀 문제</h3><ul><li>보스턴 주택 가격 데이터셋</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> keras.datasets <span style=color:#f92672>import</span> boston_housing
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(train_data, train_targets), (test_data, test_targets) <span style=color:#f92672>=</span> boston_housing<span style=color:#f92672>.</span>load_data()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 데이터 정규화</span>
</span></span><span style=display:flex><span>mean <span style=color:#f92672>=</span> train_data<span style=color:#f92672>.</span>mean(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>train_data <span style=color:#f92672>-=</span> mean
</span></span><span style=display:flex><span>std <span style=color:#f92672>=</span> train_data<span style=color:#f92672>.</span>std(axis<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>train_data <span style=color:#f92672>/=</span> std
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>test_data <span style=color:#f92672>-=</span> mean
</span></span><span style=display:flex><span>test_data <span style=color:#f92672>/=</span> std
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> keras <span style=color:#f92672>import</span> layers
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>build_model</span>():
</span></span><span style=display:flex><span>  model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>Sequential()
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dens(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(train_data<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>],)))
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>add(layers<span style=color:#f92672>.</span>Dense(<span style=color:#ae81ff>64</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>  model<span style=color:#f92672>.</span>compile(optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;rmsprop&#39;</span>, loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mse&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;mae&#39;</span>])
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> model
</span></span></code></pre></div><ul><li>K-Fold 검증을 사용한 훈련 검증</li></ul></div><script src=/js/wikilink.js></script><div><script src=https://utteranc.es/client.js repo=minuk-dev/minuk-dev.github.io issue-term=pathname theme=github-dark crossorigin=anonymous async></script></div></main><footer class=footer><div class=footer-left></div><div class=footer-right><ul class=social><li><a href=/about>About</a></li><li><a href=https://github.com/minuk-dev>Github</a></li></ul></div></footer>