<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>베이지안 통계학(Bayesian Statistics)</title><style>html body{font-family:raleway,sans-serif;background-color:#fff}:root{--accent:#00a3d2;--border-width:5px}</style><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Raleway"><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css integrity=sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN crossorigin=anonymous><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/copy-btn.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script src=/js/copy-btn.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script>$(document).on("click",function(){$(".collapse").collapse("hide")})</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-98056974-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-98056974-1")</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=google-site-verification content="g_3tJyj-KkW-_wKx7Ij5GimHV1nKPZXetCz8ydbBAfA"></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><a class="navbar-brand visible-xs" href=#>베이지안 통계학(Bayesian Statistics)
</a><button class=navbar-toggle data-target=.navbar-collapse data-toggle=collapse>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="collapse navbar-collapse"><ul class="nav navbar-nav"><li><a href=/>Home</a></li><li><a href=/wiki/>Wiki</a></li><li><a href=/posts/>Posts</a></li><li><a href=/about/>About</a></li></ul></div></div></nav><main><div class=navigator style=display:flex><div style=display:flex><div class=parent-doc style=flex:none><button class="btn btn-link" onclick='(function(e){e.querySelector("a").click()})(this)'>
<i class="fa fa-arrow-left"></i>
[[lectures]]</button></div></div></div><div><h2>베이지안 통계학(Bayesian Statistics)</h2><a href=https://github.com/minuk-dev/minuk-dev.github.io/blame/master/content/wiki/lectures/bayesian-statistics.md><h5>created : Sun, 03 Oct 2021 19:46:55 +0900</h5><h5>modified : Sat, 19 Feb 2022 17:40:46 +0900</h5></a></div><aside class=navbar id=nav-toc style=text-align:left><nav id=TableOfContents><ul><li><a href=#historical-perspective-관점의-변화>Historical Perspective (관점의 변화)</a><ul><li><a href=#en>en</a></li><li><a href=#ko>ko</a></li></ul></li><li><a href=#frequentistclassical-paradigm-빈도주의고전적-패러다임>Frequentist/Classical Paradigm (빈도주의/고전적 패러다임)</a><ul><li><a href=#en-1>en</a></li><li><a href=#ko-1>ko</a></li></ul></li><li><a href=#bayesian-paradigm-베이지안주의-패러다임>Bayesian Paradigm (베이지안주의 패러다임)</a><ul><li><a href=#en-2>en</a></li><li><a href=#ko-2>ko</a></li></ul></li><li><a href=#differences-between-frequentist-and-bayesian-빈도주의와-베이지안주의-간의-차이>Differences Between Frequentist and Bayesian (빈도주의와 베이지안주의 간의 차이)</a><ul><li><a href=#en-3>en</a></li><li><a href=#ko-3>ko</a></li></ul></li><li><a href=#overall-recommendation>Overall Recommendation</a></li><li><a href=#bayesian-approach-베이지안적-접근>Bayesian Approach (베이지안적 접근)</a><ul><li><a href=#en-4>en</a></li><li><a href=#ko-4>ko</a></li></ul></li><li><a href=#bayes-theorem>Bayes&rsquo; Theorem</a></li><li><a href=#bayesian-modeling>Bayesian Modeling</a></li><li><a href=#binomial-model>Binomial Model</a></li><li><a href=#binomial-model-with-beta-prior>Binomial Model with Beta Prior</a><ul><li><a href=#example--placenta-previa>Example : Placenta Previa</a></li></ul></li><li><a href=#posterior-predictive-distribution>Posterior Predictive Distribution</a><ul><li><a href=#example>Example</a></li></ul></li></ul><ul><li><a href=#historical-perspective>Historical Perspective</a></li></ul><ul><li><a href=#frequentistclassical-paradigm>Frequentist/Classical Paradigm</a></li><li><a href=#bayesian-paradigm-1>Bayesian Paradigm</a></li><li><a href=#differences-between-frequentist-and-bayesian>Differences Between Frequentist and Bayesian</a></li><li><a href=#overall-recommendation-1>Overall Recommendation</a></li></ul><ul><li><a href=#probabilities-defined-on-events>Probabilities Defined on Events</a></li><li><a href=#conditional-proabilities>Conditional Proabilities</a></li><li><a href=#independent-events>Independent Events</a></li><li><a href=#law-of-total-probability>Law of Total Probability</a></li><li><a href=#bayes-theorem-1>Bayes&rsquo; Theorem</a></li></ul><ul><li><a href=#bernoulli-trials>Bernoulli Trials</a></li><li><a href=#binomial-distribution>Binomial Distribution</a></li><li><a href=#multinomial-distribution>Multinomial Distribution</a></li><li><a href=#geometric-distribution>Geometric Distribution</a></li><li><a href=#negative-binomial-distribution>Negative Binomial Distribution</a></li><li><a href=#poisson-distribution>Poisson Distribution</a></li></ul><ul><li><a href=#uniform-distribution>Uniform Distribution</a></li><li><a href=#normal-distribution>Normal Distribution</a></li><li><a href=#gamma-distribution>Gamma Distribution</a></li><li><a href=#chi-square-distribution>Chi-square Distribution</a></li><li><a href=#beta-distribution>Beta Distribution</a></li></ul><ul><li><a href=#bayesian-approach-1>Bayesian Approach</a></li><li><a href=#notation>Notation</a></li><li><a href=#bayes-theorem-2>Bayes&rsquo; Theorem</a></li><li><a href=#baeysian-modeling>Baeysian Modeling</a></li></ul><ul><li><a href=#binomial-model-2>Binomial Model</a></li><li><a href=#binomial-model-with-beta-prior-1>Binomial Model with Beta Prior</a></li></ul><ul><li><a href=#posterior-predictive-distribution-2>Posterior Predictive Distribution</a></li></ul><ul><li><a href=#poisson-model-1>Poisson Model</a></li><li><a href=#posterior-predictive-distribution-of-poisson-model>Posterior Predictive Distribution of Poisson Model</a></li></ul><ul><li><a href=#normal-model-with-multiple-observations>Normal Model with Multiple Observations</a></li><li><a href=#posterior-predictive-distribution-3>Posterior Predictive Distribution</a></li><li><a href=#normal-model-with-known-mean-and-unknown-variance>Normal Model with Known Mean and Unknown Variance</a></li></ul><ul><li><a href=#noninformative-prior-distributions>Noninformative Prior Distributions</a></li><li><a href=#informative-prior-distributions>Informative Prior Distributions</a></li><li><a href=#proper--improper-prior-distributions>Proper / Improper Prior Distributions</a></li></ul><ul><li><a href=#lack-of-invariance>Lack of Invariance</a></li><li><a href=#jeffreys-noninformative-prior>Jeffreys&rsquo; Noninformative Prior</a></li></ul><ul><li><a href=#point-estimation>Point Estimation</a></li><li><a href=#frequentist-criteria-for-evaluating-estimators>Frequentist Criteria for Evaluating Estimators</a></li><li><a href=#comparing-estimators-for-proportion>Comparing Estimators for Proportion</a></li><li><a href=#posterior-mse>Posterior MSE</a></li></ul><ul><li><a href=#frequentist-confidence-interval>Frequentist Confidence Interval</a></li><li><a href=#bayesian-credible-interval>Bayesian Credible Interval</a></li><li><a href=#highest-posterior-density-hpd-credible-set>Highest Posterior Density (HPD) Credible Set</a></li></ul><ul><li><a href=#classical-p-values>Classical P-values</a></li><li><a href=#posterior-predictive-p-values>Posterior Predictive P-values</a></li></ul><ul><li><a href=#bayesian-hypothesis-testing>Bayesian Hypothesis Testing</a></li><li><a href=#bayes-factor-1>Bayes Factor</a></li><li><a href=#probabilities-of-bayes-factor>Probabilities of bayes Factor</a></li></ul><ul><li><a href=#normal-model-with-a-noninformative-prior-distribution>Normal Model with a Noninformative Prior Distribution</a></li></ul><ul><li><a href=#multinomial-model-for-categorical-data>Multinomial Model for Categorical Data</a></li><li><a href=#dirichlet-distribuiton>Dirichlet Distribuiton</a></li></ul><ul><li><a href=#multivariate-normal-model-with-known-variance>Multivariate Normal Model with Known Variance</a></li><li><a href=#conjugate-analysis>Conjugate Analysis</a></li><li><a href=#posterior-marginal-and-conditional-distribution-of-subvectors-of-mu>Posterior Marginal and Conditional Distribution of Subvectors of $\mu$</a></li><li><a href=#posterior-predictive-distribution-for-new-data>Posterior Predictive Distribution for New Data</a></li><li><a href=#noninformative-prior-density-for-mu>Noninformative Prior Density for $\mu$</a></li></ul><ul><li><a href=#hierarchical-models-1>Hierarchical Models</a></li><li><a href=#general-framework>General Framework</a></li><li><a href=#conditional-and-marginal-distributions>Conditional and Marginal Distributions</a></li><li><a href=#posterior-summaries>Posterior Summaries</a></li></ul><ul><li><a href=#hierarchical-binomial-model-1>Hierarchical Binomial Model</a></li></ul><ul><li><a href=#hierarchical-poisson-model-1>Hierarchical Poisson Model</a></li><li><a href=#hierarchinal-normal-model>Hierarchinal Normal Model</a></li></ul><ul><li><a href=#numerical-integration>Numerical Integration</a></li><li><a href=#monte-carlo-integration-1>Monte Carlo Integration</a></li></ul><ul><li><a href=#rejection-sampling-1>Rejection Sampling</a></li><li><a href=#remarks>Remarks</a></li></ul><ul><li><a href=#importance-sampling-1>Importance sampling</a></li><li><a href=#remarks-1>Remarks</a></li></ul><ul><li><a href=#markov-chains>Markov Chains</a></li></ul></nav></aside><div align=start class=content data-spy=scroll data-offset=20 data-target=#nav-toc style=position:relative><h1 id=rmarkdown>Rmarkdown</h1><ul><li>[[Bayesian/week1]]</li><li>[[Bayesian/week2]]</li><li>[[Bayesian/week3]]</li></ul><h2 id=historical-perspective-관점의-변화>Historical Perspective (관점의 변화)</h2><h3 id=en>en</h3><ul><li>Bayesian statistics came first.:<ul><li>Reverend Thomas Bayes, Pierre Simon Laplace in the late 17th/early 18th centuries.</li></ul></li><li>Limitations of Bayesian analyses:<ul><li>Difficulty in evaluating $p(\theta \vert y)$ in complex models analytically.</li><li>Role of prior information - lack of objectivity.</li></ul></li><li>Frequentist statistics was introduced as a way of overcoming these issues.:<ul><li>Fisher in the 1920s, Neyman, Pearson in the mid-20th century.</li></ul></li><li>Reemergence of Bayesian statistics:<ul><li>Computational advancements have made complex Bayesian analyses feasible.</li></ul></li></ul><h3 id=ko>ko</h3><ul><li>베이지안 방법론이 처음 토마스 베이지와 시몬 라플라스에 의해 17세기 말, 18세기 초에 등장했다.</li><li>베이지안 분석은 복잡한 모델에 대해서 사후 확률을 추론하기 어려웠고, 사전 정보의 역할이 객관성의 저하를 불러 한계에 부딪혔다.</li><li>Fisher(1920), Neyman, Pearson(20세기 중기)와 같은 빈도주의자들이 이러한 문제를 극복하는 방법론을 제시했다.</li><li>계산의 혁신(컴퓨터의 발전)에 따라서 복잡한 베이지안 분석론이 실용성이 생기게 되어서 재등장하게 된다.</li></ul><h2 id=frequentistclassical-paradigm-빈도주의고전적-패러다임>Frequentist/Classical Paradigm (빈도주의/고전적 패러다임)</h2><h3 id=en-1>en</h3><ul><li>A parameter $\theta$ is viewed as an unknown fixed constant.</li><li>Data are a repeatable random sample.</li><li>Goal : Estimate $\theta$ based on all available information (data) and find its associated error under asymptotic theory.</li><li>Inference is based on examining how well a procedure would do if it is used many times.:<ul><li>Point estimates and standard errors or 95% confidence intervals.</li><li>Deduction from $P(data \vert H_0)$, by setting $\alpha$ in advance.</li><li>Accept $H_1$ if $P(data \vert H_0) &lt; \alpha$</li><li>Accept $H_0$ if $P(data \vert H_1) \ge \alpha$</li></ul></li></ul><h3 id=ko-1>ko</h3><ul><li>추정하고자 하는 파라메터(이걸 모수로 번역해도 되나?) $\theta$를 우리가 아직 알지는 못하지만 고정된 값이라고 생각한다.</li><li>따라서 데이터는 반복가능한 랜덤 샘플이 된다. (이미 집단이 결정되어 있고 우리는 거기에 영향을 주지 못해서 데이터 추출을 몇번을 해도 똑같다는 것)</li><li>목표 : 사용가능한 모든 정보(data)에 기반하여 $\theta$를 추정하고 점근적 이론하에 이와 관련된 에러를 찾아낸다.</li><li>추정은 여러번 사용할때 얼마나 잘 적용되는지 시험하고 한다.</li><li>-> 최대한 많이 맞출수 있도록 한다.</li></ul><h2 id=bayesian-paradigm-베이지안주의-패러다임>Bayesian Paradigm (베이지안주의 패러다임)</h2><h3 id=en-2>en</h3><ul><li>A parameter $\theta$ is viewed as a random variable whose distribution is unknown, and described probabilistically .</li><li>Data are observed from the realized sample.</li><li>Goal: Estimate the distribution of $\theta$ conditional on the observed data, the posterior distribution of $\theta$.</li><li>Inference is based on summaries of the posterior distribution of $\theta$.:<ul><li>Induction from $P(\theta \vert data)$, starting with $P(\theta)$</li><li>Broad descriptions of the posterior distribution such as means and quantiles.</li><li>Highest posterior density intervals indicating region of highest posterior probability, regardless of contiguity.</li></ul></li></ul><h3 id=ko-2>ko</h3><ul><li>파라메터 $\theta$를 우리가 모르는 분포를 따르는 랜덤 변수라고 보고, 확률적으로 설명 가능하다고 본다.</li><li>데이터는 구체화된(실현된으로 번역하기에는 어렵&mldr; realized) 샘플로 부터 관측된다.</li><li>-> 이게 번역이 참 어렵다. 한국어로 어캐 말하지?</li><li>목표 : 관측된 데이터로부터 $\theta$의 조건부 분포를 추정한다. ($\theta$의 사후분포를 추정한다.)</li><li>추론은 $\theta$의 사후분포에 기반해서 진행된다.:<ul><li>평균, 분위수과 같은 다양한 통계 수치 등 사후분포에 관한 폭넓은 설명이 가능하다.</li><li>연속성 여부에 관계없이 사후 밀도가 높을수록 높은 사후 확률을 가지는 것을 의미한다. -> 연속성 여부와 관련없이 적용가능하다.</li></ul></li></ul><h2 id=differences-between-frequentist-and-bayesian-빈도주의와-베이지안주의-간의-차이>Differences Between Frequentist and Bayesian (빈도주의와 베이지안주의 간의 차이)</h2><h3 id=en-3>en</h3><ul><li>Waht is fixed?:<ul><li>Frequentist : Parameters are fixed!</li><li>Bayesian : Data are fixed!</li></ul></li><li>General inference:<ul><li>Frequentist : $P(data \vert \theta)$ is the sampling distribution of the data given the parameter.</li><li>Bayesian : $P(\theta)$ is the prior distribution of the parameter (before the data are seen) and $P(\theta \vert data)$ is the posterior distribution of the parameter.</li></ul></li><li>95% Intervals:<ul><li>Frequentist: In repeated sampling, 95% of realized intervals covers the true parameter.</li><li>Bayesian: For these data, with probability 95% the parameter is in the interval.</li></ul></li><li>Bayesian inference proceeds vertically, with x fixed, according to the posterior distribution $g(\mu \vert x)$.</li><li>Frequentists reason horizontally, with $\mu$ fixed and x varying.</li></ul><h3 id=ko-3>ko</h3><ul><li>뭐를 고정됬다고 볼것인가? 빈도주의는 파라메터를, 베이지안주의는 데이터를 고정된다고 본다.</li><li>예: &ldquo;민욱공정&rdquo; 이라는 회사에서 일회용 컵을 생산하는 기계를 만들어낸다고 하자. &ldquo;민욱공정"에서 만들어 내는 기계는 오차율이 정규분포(0.001, 0.0004)를 따른다고 하자. 이 기계를 구입해서 실제로 일회용 컵 10000개를 생산했고, 10개의 불량품을 만들었다, 이 기계의 오차율은 어떻게 될까?:<ul><li>빈도주의자들은 기계의 오차율은 고정되어 있고, 관측된 데이터가 10개의 불량품을 포함하는 샘플이 추출되었다고 본다. (역으로 추론할 때는 이를 통해서 오차율에 대한 가정을 기각할지 받아들일지 결정한다.)</li><li>베이지안 주의자들은 기계의 오차율은 변화한다고 보고, 불량품의 개수가 기계의 오차율을 결정한다고 본다.</li></ul></li><li>뭔가 너무 어렵게 설명한거 같기도 한데, 둘다 맞는 말로 볼 수 있다. 무엇이 무엇을 결정할지에 대한 관점이 달라진 것이다.</li><li>살짝 다른 이야기이지만, 가설검증에서 느낀 찝찝한 감정이 이런 점에서 나오는 것이다.:<ul><li>가설검증에서 통과되는 가설이 여러개인 경우에 대한 찝찝함을 느껴본적이 있나? 이를 베이지안 관점에서 보면, 빈도주의에서 통과시키는 가설이 분포로 존재함을 추론해낼수 있다.</li></ul></li></ul><h2 id=overall-recommendation>Overall Recommendation</h2><ul><li>Be pragmatic, not dogmatic.:<ul><li>Use what has been shown to work.</li><li>As a default approach, the following will serve you well:<ul><li>Design as a bayesian, and evaluate as a frequentist</li></ul></li></ul></li><li>Construct models and procedures from a Bayesian perspective, and use frequentist tools to evaluate their empirical and theoretical perofrmance.</li><li>In the spirit of being pragmatic, it might seem unnecessarily restrictive to limit oneself to Bayesian procedures, and indeed, there are times when a non-Bayesian procedure may be preferable to a Bayesian one.</li><li>However, typically, it turns out that there is no disadvantage in considering only Bayesian procedures.</li></ul><h2 id=bayesian-approach-베이지안적-접근>Bayesian Approach (베이지안적 접근)</h2><h3 id=en-4>en</h3><ul><li>The idea is to assume a prior probability distribution for $\theta$; that is, a distribution representing the plausibility of each possible value of $\theta$ before the data are observed.</li><li>To make inferences about $\theta$, one simply considers the conditional distribution of $\theta$ given the observed data, referred to as the posterior distribution, representing the plausibility of each possible value of $\theta$ after seeing the data.</li><li>This provides a coherent framework for making inferences about unknown parameters $\theta$ as well as any future data or missing data, and for making rational decisions based on such inferences.</li></ul><h3 id=ko-4>ko</h3><ul><li>$\theta$의 사전 확률을 가정하는 것이 기본 아이디어이다. 데이터를 관측하기 전 $\theta$의 그럴듯한 가능한 값을 나타내는 분포를 설정해야한다.</li><li>$\theta$에 대한 추론을 하기 위해서, 관측된 데이터 하에 $\theta$의 조건부 분포(사후 분포)를 간단하게 고려한다. 이는 데이터 관측 이후 $\theta$의 가능한 값들의 그럴듯함을 표현한다.</li><li>이러한 과정을 통해서 미래의 어떤 관측값이나 유실된 데이터에 대해서도 $\theta$를 추론할 논리적인 체계를 만들어 낸다. 또한 이러한 추론을 기반으로 하여 이성적인 결정을 한다.</li></ul><h2 id=bayes-theorem>Bayes&rsquo; Theorem</h2><ul><li>Bayes&rsquo; Theorem:<ul><li>$p(\theta \vert y) = \frac{p(\theta, y)}{p(y)} = \frac{p(y \vert \theta) p (\theta)}{p(y)}$</li><li>where $p(y)$ is marginal distribution of y and either $p(y) = \sum_{\theta} p(\theta)p(y\vert\theta)$ or $p(y) = \int p(\theta) p(y \vert \theta) d \theta$.</li></ul></li><li>In calcuating,:<ul><li>$p(\theta \vert y) \propto p(y \vert \theta) p(\theta)$</li></ul></li></ul><h2 id=bayesian-modeling>Bayesian Modeling</h2><ol><li>Model specification:</li></ol><ul><li>$p(y \vert \theta)$ : likelihood function of y</li><li>$p(\theta)$ : prior distribution of $\theta$</li></ul><ol start=2><li>Performing inference:</li></ol><ul><li>$p(\theta \vert y)$ : posterior distribution of $\theta$ given y</li><li>$p(\theta \vert y) \propto p(y \vert \theta) p(\theta)$</li><li>How ?:<ul><li>analystically-only possibile for certain models.</li><li>using simulation when we are not able to write down the exact form of the posterior density.</li></ul></li></ul><ol start=3><li>Inference results:</li></ol><ul><li>ex) posterior mean : $E[\theta \vert y] = \int _{\theta} \theta p(\theta \vert y) d \theta$</li></ul><h2 id=binomial-model>Binomial Model</h2><ul><li>Goal: estimate an unknown proportion from the results of a sequence of &ldquo;Bernoulli trials&rdquo; (data $y_1, &mldr;, y_n$ that are either 1s or 0s)</li><li>Assume that the data arise from a sequence of n independent trials or draws from a large population where each trial is classified as a &ldquo;success&rdquo; ($y_i = 1$) or a &ldquo;failure&rdquo; ($y_i = 0$).</li><li>We can characterize the data by the total number of success, denoted by y, in n tirals.</li><li>Binomial sampling model:<ul><li>$p(y \vert \theta) = Bin(y \vert n, \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}$</li><li>where the parameter $\theta$ represents the proportion of successes in the population (equivalently, the probability of success in each trial).</li></ul></li><li>Question: How can we get the posterior distribution of $\theta$?</li><li>First, we need to specify the prioir distribution for $\theta$:<ul><li>One possibility: $p(\theta) = Unif(0, 1)$</li></ul></li><li>Second, apply Bayes&rsquo; Rule:<ul><li>Posterior distribution:<ul><li>$p(\theta \vert y) \propto p(\theta) p(y \vert \theta) \\ = I(0 \le \theta \le 1) \binom{n}{y} \theta^y (1 - \theta)^{n - y} \\ \propto I(0 \le \theta \le 1) \theta^y (1 - \theta)^{n - y} ~ Beta(y + 1, n - y + 1)$</li><li>It means the posterior distribution follows the Beta(y + 1, n - y + 1) distribution.</li></ul></li><li>Posterior mean:<ul><li>$Beta(\alpha, \beta)$ distribution has $\mu = \frac{\alpha}{\alpha + \beta}$ as mean.</li><li>So, Binimial model&rsquo;s posterior mean is $\frac{y + 1}{n + 2}$:<ul><li>$\frac{y + 1}{n + 2} = \frac{n}{n + 2} \frac{y}{n} + \frac{1}{n + 2} \\ = \text{weight} \times \text{MLE} + \text{weight} \times \text{ Prior information }$</li><li>Weighted average of sample mean and prior mean</li></ul></li></ul></li></ul></li></ul><h2 id=binomial-model-with-beta-prior>Binomial Model with Beta Prior</h2><ul><li>Use the different prior distribution:<ul><li>$p(\theta) = Beta(\alpha, \beta)$</li></ul></li><li>Posterior distribution:<ul><li>$p(\theta \vert y) \propto p(\theta) p(y \vert \theta) \\ = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta^{\alpha - 1} (1 - \theta)^{\beta - 1} \binom{n}{y} \theta ^ y (1 - \theta)^{n - y} \\ \propto \theta^{\alpha - 1 + y} (1 - \theta)^{\beta - 1 + n - y} ~ Beta(\alpha + y, \beta + n - y)$</li></ul></li><li>Posterior mean:<ul><li>$E[\theta \vert y] = \frac{\alpha + y}{\alpha + \beta + n} = \frac{n}{\alpha + \beta + n} \frac{y}{n} + \frac{\alpha + \beta}{\alpha + \beta + n} \frac{\alpha}{\alpha + \beta}$</li><li>It is also weighted average of sample mean and prior mean</li><li>Actually, unif(0, 1) = Beta(1, 1)</li></ul></li><li>Observations:<ul><li>When n is greater, the expectation goes to sample mean.</li><li>When n is smaller, the expectation goes to prior mean.</li><li>We can interpret $\alpha + \beta$ is the amount of prior information:<ul><li>When $\alpha + \beta$ is greater (more information of prior), the expectation goes to prior mean.</li></ul></li></ul></li></ul><h3 id=example--placenta-previa>Example : Placenta Previa</h3><ul><li><p>Placenta previa is an unusual pregnancy condition in hwich the placenta is implmented very low in the uterns, obstructing the fetus from a normal vaginal delivery.</p></li><li><p>A study of the sex of placentas previa births in Germany found that there were 437 femals among 980 births.</p></li><li><p>How much evidence does this data provide for the claim that the proportion of female births in the population is less than the proportion of female births in the general population, which is approximately 0.485?:</p><ul><li>Freq:<ul><li>$Y = # \text{females} ~ Bin(980, \theta)$</li><li>$\hat \theta_{ML} = \frac{y}{n} = 0.446$</li><li>$H_0 : \theta = 0.485$</li><li>$H_1 : \theta &lt; 0.485$</li><li>$Z = \frac{0.446 - 0.485}{\sqrt{\frac{0.485(1 - 0.485)}{980}}} = -2.44 &lt; -1.65$</li><li>Reject $H_0$</li></ul></li></ul></li><li><p>Let $\theta$ be the probability of a female births among placenta previa pregnancies. What do we need to calculate?:</p><ul><li>Assumming a uniform prior what is $p(\theta \vert y)$?:<ul><li>$\theta ~ Unif(0, 1)$</li><li>$y = 437, n = 980$</li><li>$\theta \vert y ~ Beta(y + 1, n - y + 1) = Beta(438, 544)$</li></ul></li></ul></li><li><p>What is the posterior mean of $\theta$?:</p><ul><li>$\hat \theta_{Bayes} = E[\theta \vert y] = \frac{438}{438 + 544} = 0.446$</li><li>Whey they are similar? n is large!</li></ul></li><li><p>What is the posterior standard deviation of $\theta$?:</p><ul><li>$\sqrt{Var(\theta \vert y)} = \sqrt{\frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}} = 0.016$</li></ul></li><li><p>What is the 95% posterior interval?:</p><ul><li>integration:<ul><li>$\int_{a}^{b} p(\theta \vert y) d \theta = 0.95$</li><li>find a, b</li></ul></li><li>normal approximation:<ul><li>$0.446 \pm 1.96 * 0.016 \sim [0.415, 0.477]$ not include 0.485</li></ul></li><li>numerical method (quantile - base C.I):<ul><li>draw 1000 samples from $p(\theta \vert y)$</li><li>find 25th, 975th values => $[0.415, 0.476]$</li></ul></li><li>HPD(Highest Posterior Density) Interval</li></ul></li><li><p>Use different prior distributions:</p><ul><li>$\theta ~ Beta(\alpha, \beta)$</li><li>=> $\theta \vert y ~ Beta(437 + \alpha, 543 + \beta)$</li></ul></li><li><p>The sensitivity of posterior inference about $\theta$ to the proposed prior distrubiotn is show blow:</p><ul><li>prior information is not sensitive since n is large.</li></ul></li></ul><h2 id=posterior-predictive-distribution>Posterior Predictive Distribution</h2><ul><li>After the data y have been observed, we can predict an unknown observable $\tilde y$</li><li>The posterior predictive distribution of a future observation, $\tilde y$ is:<ul><li>$p(\tilde y \vert y) = \int p(\tilde y, \theta \vert y) d \theta \\ = \int p(\tilde y \vert \theta, y) p (\theta \vert y) d \theta \\ = \int p(\tilde y \vert \theta) p (\theta \vert y) d \theta$</li></ul></li><li>Assumed $y$ and $\tilde y$ are conditional independent given $\theta$.</li><li>prior predictive distribution before y observed => $p(\tilde y) = \int p(\tilde y, \theta) d \theta \\ = \int p(\tilde y \vert \theta) p(\theta) d \theta$</li></ul><h3 id=example>Example</h3><ul><li>Binomial model:<ul><li>$y_i ~^{iid} Bern(\theta)$</li><li>$Y ~ Bin(n, \theta), 0 \le \theta \le 1$</li><li>$\theta ~ Unif(0, 1)$</li></ul></li></ul><hr><h1 id=bayesian-statistics>Bayesian Statistics</h1><hr><ul><li>Course Description:<ul><li>Main goal : understand the basic ideas of Bayesian theory and methods, and the essential distinctions between Frequentiest and Bayesian methods.</li><li>Key topics: Bayesian inference, conjugate prior distribution, informative prior, Bayesian hypothesis testing, Markov chain Monte Carlo, Gibbs sampler, Metropolis-Hastings algorithm, and applications in the real world.</li><li>Students are expected to understand Bayesian statistical methods, compare with Frequentist methods, apply them to real data and interpret the results.</li></ul></li></ul><hr><h1 id=bayesian-paradigm>Bayesian Paradigm</h1><h2 id=historical-perspective>Historical Perspective</h2><ul><li>Bayesian statistics came first:<ul><li>Reverend Thomas Bayes, Pierre Simon Laplace in the late 17th/early 18th centuries.</li></ul></li><li>Limitations of Bayesian analyses:<ul><li>Difficulty in evaluationg $p(\theta \vert y)$ in complex models analytically.</li><li>Role of prior information - lack of objectivity.</li></ul></li><li>Frequentist statistics was introduced as a way of overcoming these issues.:<ul><li>Fisher in the 1920s, Neyman, Pearson in the mid-20th century.</li></ul></li><li>Reemergence of Bayesian statistics:<ul><li>Computational advancements have made complex Bayesian analyses feasible.</li></ul></li></ul><h1 id=frequentist-vs-bayesian>Frequentist vs. Bayesian</h1><h2 id=frequentistclassical-paradigm>Frequentist/Classical Paradigm</h2><ul><li>A parameter $\theta$ is viewd as an unknown fixed constant.</li><li>Data are a repeatable random sample</li><li>Gogal : Estimate $\theta$ based on all avaiable information (data) and find its associated error under asymptotic theory.</li><li>Inference is based on examining how well a procedure would do if it is used many times:<ul><li>Point estimates and standard errors or 95% confidence intervals.</li><li>Deduction from $P(data \vert H_0)$, by setting $\alpha$ in advance.</li><li>Accept $H_1$ if $P(data \vert H_0) &lt; \alpha$.</li><li>Accept $H_0$ if $P(data \vert H_0) \ge \alpha$.</li></ul></li></ul><h2 id=bayesian-paradigm-1>Bayesian Paradigm</h2><ul><li>A parameter $\theta$ is viewed as a random variable whose distribution is unknown, and described probabilistically.</li><li>Data are observed from the realized sample.</li><li>Goal: Estimate the distribution of $\theta$ conditional on the observed data, the posterior distirbution of $\theta$.</li><li>Inference is based on summaries of the posterior distribution of $\theta$.:<ul><li>Induction from $P(\theta \vert data)$, starting with $P(\theta)$</li><li>Broad descriptions of the posterior distribution such as means and quantiles.</li><li>Highest posterior density intervals indicating region of highest posterior probability, regardless of contiguity.</li></ul></li></ul><h2 id=differences-between-frequentist-and-bayesian>Differences Between Frequentist and Bayesian</h2><ul><li><p>What is fixed?:</p><ul><li>Frequentist: Parameters are fixed</li><li>Bayesian : Data are fixed</li></ul></li><li><p>General inference:</p><ul><li>Frequentist : $P(data \vert \theta)$ is the sampling distribution of the data given the parameter.</li><li>Bayesian : $P(\theta)$ is the prior distribution of the parameter (before the data are seen) and $P(\theta \vert data)$ is the posterior distribution of the parameter.</li></ul></li><li><p>95% Intervals:</p><ul><li>Frequentist : In repeated sampling, 95% of realized intervals covers the true parameter.</li><li>Bayesian : For these data, with probability 95% the parameter is in the interval.</li></ul></li><li><p>Bayesian inference proceeds vertically, with $x$ fixed, according to the posterior distribution $g(\mu \vert x)$.</p></li><li><p>Frequentists reason horizontally, with $\mu$ fixed and $x$ varying.</p></li></ul><h2 id=overall-recommendation-1>Overall Recommendation</h2><ul><li>Be pragmatic, not dogmatic:<ul><li>Use what has been shown to work.</li><li>As a default approach, the followign will serve you well:<ul><li>Design as a Bayesian, and evaluate as a frequentist</li></ul></li></ul></li><li>Construct models and procedures from a Bayesian perspective, and use frequentist tools to evaluate their empirical and theoretical performance.</li><li>In the spirit of being pragmatic, it might seem unnecessarily restrictive to limit oneself to Bayesian procedures, and indeed, there are times when a non-Bayesian Procedure may be preferable to a Bayesian one.</li><li>However, typically, in turns out that there is no disadvantage in cnosidering only Bayesian procedures.</li></ul><h1 id=probability-review>Probability Review</h1><h2 id=probabilities-defined-on-events>Probabilities Defined on Events</h2><ul><li>Consider an experiment whose sample space is $S$. For each event $A$ of the sample space $S$, we assume that a number $P(A)$ is defined and satisfies the following three conditions:<ol><li>$0 \le P(A) \le 1$</li><li>$P(S) = 1$</li><li>For any sequence of events $A_1, A_2, &mldr;$ that are pariwise mutually exclusive, that is, events for which $A_n \cap A_m = \phi$ when $n \not = m$, then:
$$ P(\Cup_{n=1}^\infty A_n) = \sum_{n=1}^\infty P(A_n)$$
We refere to $P(A)$ as the proability of the event A.</li></ol></li></ul><h2 id=conditional-proabilities>Conditional Proabilities</h2><ul><li>If the event $B$ occurs, thenm in order for $A$ to occur it is necessary for the actual occurrence to be apoint in both $A$ and in $B$, that is, it must be in $A \cap B$. Now, because we know that $B$ has occurred, it follows that $B$ becomes our new sample space and hence the probability that the event $A \cap B$ occurs will equal the probability of $A \cap B$ relative to the probability of $B$. That is,
$$ P(A \vert B) = \frac{P(A \cap B)}{P(B)}$$</li></ul><h2 id=independent-events>Independent Events</h2><ul><li>Two events $A$ and $B$ are said to be independent if
$$ P(A \cap B) = P(A) P(B) $$
which implies
$$ P(A\vert B) = P(A)$$
$$ P(B \vert A) = P(B)$$</li><li>More generally, the events $A_1, A_2, &mldr;, A_n$ are said to be independent if for every subset $A_{1&rsquo;}, A_{2&rsquo;}, &mldr;, A_{r&rsquo;}$, $r \le n$, of these events
$$ P(A_{1&rsquo;}, A_{2&rsquo;}, &mldr; , A_{r&rsquo;}) = P(A_{1&rsquo;}) P(A_{2&rsquo;}) \cdots P(A_{r&rsquo;})$$</li></ul><h2 id=law-of-total-probability>Law of Total Probability</h2><ul><li>If events $A_1, &mldr;, A_k$ partition a sample space $S$ into mutually exclusive and exhaustive nonempty events, then the Law of Total Probabiilty states that the total probability of an event B is given by
$$
\begin{aligned}
P(B) &= P(A_1 \cap B) + P(A_2 \cap B) + \cdots + P(A_k \cap B) \
&= P(B \vert A_1) P(A_1) + P(B \vert A_2) P(A_2) + \cdots + P(B \vert A_k)P(A_k) \
&= \sum_{j=1}^k P(B \vert A_j) P(A_j)
\end{aligned}
$$</li></ul><h2 id=bayes-theorem-1>Bayes&rsquo; Theorem</h2><ul><li>Bayes&rsquo; Theorem provides a method for invertin conditional probabilities. In its simplest form, if $A$ and $B$ are events and $P(B) > 0$, then
$$P(A\vert B) = \frac{P(B \vert A) P(A)}{P(B)}$$</li></ul><h1 id=discrete-distributions>Discrete Distributions</h1><h2 id=bernoulli-trials>Bernoulli Trials</h2><ul><li>Several discrete distributions can formulated in terms of the outcomes of Bernoulli tirals.</li><li>A Bernoulli trial has exactly two possible outcomes, &ldquo;success&rdquo; or &ldquo;failure&rdquo;. A Bernoulli random variable $X$ has the probability mas function<ul><li>$P(X = 1) = p$ and $P(X=0) = 1 - p$</li><li>where p is the probability of success, $0 \le p \le 1$</li></ul></li></ul><h2 id=binomial-distribution>Binomial Distribution</h2><ul><li>Suppose that $X$ records the number of successes in n iid Bernoulli tirals with success probability $p$. Then $X$ has the $Binomial(n, p)$ distribution with
$$
\begin{aligned}
P(X = x) & = \binom{n}{x} p^x (1- p)^{n-x} \
& = \frac{n!}{x!(n-x)!} p^x(1-p)^{n-x}, & x=0,1,&mldr;,n
\end{aligned}
$$</li><li>Then mean and variance are<ul><li>$E[X] = np$ and $Var(X) = np(1 - p)$</li></ul></li></ul><h2 id=multinomial-distribution>Multinomial Distribution</h2><ul><li>A multinomial distribution is a generalization of the binomial distribution</li><li>Suppose one does an experiment of extracting n balls of k different colors from a bag, replacing the extracted ball after each draw. Balls from the same color are equivalent. Denote the variable which is the number of extracted balls of color $i(i=1,&mldr;k)$ as $X_i$, and denotes as $p_i$, the probability that a given extraction will be in color $i$. THen $X_1, &mldr;, X_k$ has the multinomial distribution with joint pmf
$$\begin{aligned}
f(x_1, &mldr;, x_k) & = P(X_1 = x_1, &mldr;, X_k = x_k) \
& = \begin{cases} \frac{n!}{x_1! \cdots x_k!} p_1^{x_1} \times \cdots \times p_k^{x_k} & \text{ when } \sum_{i=1}^k x_k = n \
0 & otherwise \end{cases}
\end{aligned}
$$</li><li>It follows that $E[X_i] = np_i$, $Var(X_i) = np_i (1-p_i)$, $Cov(X_i, X_j) = -np_i p_j, \text{ for } i \not = j$</li></ul><h2 id=geometric-distribution>Geometric Distribution</h2><ul><li><p>Suppose that independent Bernoulli trials, each having probability $p$ of being a success, are performed until a scucess occurs. If we let $X$ be the number of trials required until the first success, then $X$ has the geometric distribution with pmf
$$ \begin{aligned}P(X = x) &= (1-p)^{x-1}p,& x = 1,2, &mldr;\end{aligned}$$</p></li><li><p>The cdf of $X$ is
$$ F(x) = P(X \le x) = 1 - (1 - p)^x$$</p></li><li><p>It follows that $E[X] = \frac{1}{p}$ and $Var(X) = \frac{1-p}{p^2}$</p></li></ul><h2 id=negative-binomial-distribution>Negative Binomial Distribution</h2><ul><li>The distribution that applies to the random variable $X$ equal to the number of the trial on which the $r$th success occurs (r = 2, 3, 4, etc) is the negative binomial distribution with pmf
$$\begin{aligned}P(X=x) &= \binom{x - 1}{r - 1} p^r (1- p)^{x-r}, & x = 1, r+ 1, r+ 2&mldr; \end{aligned}$$</li><li>The geometric distribution is a special case of the negative binomial distribution with $r=1$.</li><li>It follows that $E[X] = \frac{r}{p}$ and $Var(X) = \frac{r(1-p)}{p^2}$</li></ul><h2 id=poisson-distribution>Poisson Distribution</h2><ul><li>The Poisson distribution is a discrete probability distribution that expresses the probability of a given number $X$ of events occuring in a fixed interval of time and/or space with pmf
$$\begin{aligned} P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}, & x = 0,1,2,&mldr; \end{aligned}$$
where $\lambda > 0$ is the average value of $X$.</li><li>It follows that $E[X] = \lambda$ and $Var(X) = \lambda$</li></ul><h1 id=continuous-distributions>Continuous Distributions</h1><h2 id=uniform-distribution>Uniform Distribution</h2><ul><li>If $\theta_1 &lt; \theta_2$, a random variable $X$ is said to have a continuous uniform distribution on the interval $(\theta_1, \theta_2)$ with pdf
$$ f(x) = \begin{cases} \frac{1}{\theta_2 - \theta_1}, & \theta_1 \le x \le \theta_2 \ 0, & \text{otherwise}\end{cases}$$</li><li>It follows that $E[X] = \frac{\theta_1 + \theta_2}{2}$ and $Var(X) = \frac{(\theta_2 - \theta_1)^2}{12}$</li></ul><h2 id=normal-distribution>Normal Distribution</h2><ul><li>The normal distribution with mean $\mu$ and variance $\sigma^2$ is the continuous distribution with pdf
$$ \begin{aligned}f(x) &= \frac{1}{\sqrt{2 \pi} \sigma} exp{ - \frac{1}{2} (\frac{x - \mu}{\sigma})^2}, & -\infty &lt; x &lt; \infty\end{aligned}$$</li><li>The standard normal distribution $N(0,1)$ has zero mean and unit variance, and the standard normal cdf is
$$\begin{aligned} \Phi(z) &= \int_{-\infty}^z \frac{1}{\sqrt{2 \pi}} e^{-t^2 / 2} dt, & -\infty &lt; z &lt; \infty \end{aligned}$$</li><li>Linear combinations of normal variables are normal; if $X_1, &mldr;, X_k$ are independent, $X_i \sim N(\mu_i, \sigma_i^2)$, and $a_1, &mldr;, a_k$ are constants, then
$$Y = a_1 X_1 + \cdots + a_k X_k$$
is normally distributed with mena $\mu = \sum_{i=1}^k a_i \mu_i$ and variance $\sigma^2 = \sum_{i=1}^k a_i^2 \sigma_i^2$</li></ul><h2 id=gamma-distribution>Gamma Distribution</h2><ul><li><p>A random variable $X$ is said to have a gamma distribution with parameters $\alpha > 0$ and $\beta > 0$ with pdf
$$ f(x) = \begin{cases} \frac{1}{\Gamma(\alpha) \beta^{\alpha}} x^{\alpha - 1} e^{- x / \beta}, & 0 \le x &lt; \infty \ 0, & \text{elsewhere}\end{cases}$$</p></li><li><p>It follows that $E[X] = \alpha \beta$ and $Var(X) = \alpha \beta^2$</p></li><li><p>$\alpha$ : shape, $\beta$ : scale</p></li></ul><h2 id=chi-square-distribution>Chi-square Distribution</h2><ul><li>A random variable $X$ is said to have a chi-square distribution with $v$ degrees of freedom with pdf
$$f(x) \frac{1}{\Gamma(v/2) 2^{v/2}} x^{v/2 - 1} e^{- x / 2}$$
where $v$ is a positive integer</li><li>$\chi^2(v)$ is a special case of the gamma distribution, with shape parameter $v/2$ and scale parameter $2$.</li><li>It follows that $E[X] = v$ and $Var(X) = 2v$</li><li>It $Z_1, &mldr;, Z_v$ are iid standard normal then:
$$ Z_1^2 + \cdots + Z_v^2 \sim \chi^2(v)$$</li></ul><h2 id=beta-distribution>Beta Distribution</h2><ul><li><p>A random variable $X$ is said to have a beta distribution with parameters $\alpha > 0$ and $\beta > 0$ with pdf
$$ f(x) = \begin{cases} \frac{1}{B(\alpha, \beta)} x^{\alpha - 1} (1-x)^{\beta - 1}, & 0 \le x \le 1 \ 0, & \text{elsewhere} \end{cases}$$
where
$$B(\alpha, \beta) = \int_0^1 x^{\alpha - 1}(1-x)^{\beta - 1} dx = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}$$</p></li><li><p>It follows that $E[X] = \frac{\alpha}{\alpha + \beta}$ and $Var(X) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$</p></li><li><p>$\alpha, \beta$ : shape</p></li></ul><h1 id=bayesian-approach>Bayesian Approach</h1><h2 id=bayesian-approach-1>Bayesian Approach</h2><ul><li><p>A parameter $\theta$ is viewd as a random variable whose distribution is unknown.</p></li><li><p>Data are observed from the realized sample</p></li><li><p>Goal: Estimate the distribution of $\theta$ conditional on the observed data, the posterior distribution of $\theta$.</p></li><li><p>Inference is based on summaries of the posterior distribution of $\theta$:</p><ul><li>Induction from $P(\theta \vert data)$, starting with $P(\theta)$</li><li>$P(\theta)$ is the prior distribution of the parameter (before the data are observed) and $P(\theta \vert data)$ is the posterior distribution of the parameter (after the data are observed).</li><li>Broad descriptions of the posterior distribution such as means and quantiles.</li></ul></li><li><p>The ida is is to assume a prior probability distribution for $\theta$; that is, a distribution representing the plausibility of each possible value of $\theta$ before the data are observed.</p></li><li><p>To make inferences about $\theta$, one simply considers the conditional distribution of $\theta$ given the observed data, referred to as the posterior distribution, representing the plausibility of each possible value of $\theta$ after seeing the data.</p></li><li><p>This provides a coherent framework for making inferences about unknown parameters $\theta$ as well as any future data or missing data, and for making rational decisions based on such inferences.</p></li></ul><h2 id=notation>Notation</h2><ul><li>$\theta$ : parameter</li><li>$y$: observed data</li><li>$p(y \vert \theta)$ : likelihood function of y</li><li>$p(\theta)$ : prior distribution</li><li>$p(\theta \vert y)$ : posterior distribution of $\theta$ given y</li></ul><h2 id=bayes-theorem-2>Bayes&rsquo; Theorem</h2><ul><li><p>Bayes&rsquo; Theorem
$$p(\theta \vert y) = \frac{p(\theta, y)}{p(y)} = \frac{p(y \vert \theta) p(\theta)}{p(y)}$$
where $p(y)$ is marginal distribution of y and either $p(y) = \sum_\theta p(\theta) p(y \vert \theta)$ or $p(y) = \int p(\theta) p(y \vert \theta) d \theta$.</p></li><li><p>In calculating,
$$ p(\theta \vert y) \propto p(y \vert \theta) p(\theta)$$</p></li></ul><h2 id=baeysian-modeling>Baeysian Modeling</h2><ol><li>Model specification:</li></ol><ul><li>$p(y \vert \theta)$ : likelihood function of y</li><li>$p(\theta)$ : prior distribution of $\theta$</li></ul><ol start=2><li>Performing inference</li></ol><ul><li>$p(\theta \vert y)$ : posterior distribution of $\theta$ given y</li><li>$p(\theta \vert y) \propto p(y \vert \theta) p(\theta)$</li><li>How?<ul><li>analytically-only possible for certain models.</li><li>using simulation when we are not able to write down the exact form of the posterior density.</li></ul></li></ul><ol start=3><li>Inference results</li></ol><ul><li>ex) posetrior mean : $E[\theta \vert y] = \int_\theta \theta p(\theta \vert y) d \theta$</li></ul><h1 id=binomial-model-1>Binomial Model</h1><h2 id=binomial-model-2>Binomial Model</h2><ul><li><p>Goal : estimate an unknown proportion from the results of a sequence of &ldquo;Bernoulli trials&rdquo; (data $y_1, &mldr;, y_n$ that are either 1s or 0s)</p></li><li><p>Assume that the data arise from a sequence of n independent trials or draws from a large population where each trial is classified as a &ldquo;success&rdquo; ($y_i = 1$) or a &ldquo;failure&rdquo; ($y_i = 0$).</p></li><li><p>We can characterize the data by the total number of success, denoted by $y$, in $n$ trials.</p></li><li><p>Binomial sampling model
$$ p(y \vert \theta) = Bin(y \vert n, \theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}$$
where the parameter $\theta$ represents the proportion of successes in the population (equivalently, the probability of success in each trial).</p></li><li><p>cf. Frequentist:
$$L\theta \vert y) = \binom{n}{y} \theta^y (1- \theta)^{n-y}$$
$$\frac{\partial log L}{\partial \theta} = \frac{y}{\theta} - \frac{n - y}{1 - \theta} = 0$$
$$ \Rightarrow \hat \theta_{ML} = \frac{y}{n} = \bar y$$</p><ul><li>$$\hat \theta_{ML} \overset{app}{\sim} N(\theta, \frac{\theta(1 - \theta)}{n})$$</li></ul></li><li><p>Question : How can we get the posteriro distribution of $\theta$?</p></li><li><p>First, we need to specify the prior distribution for $\theta$. One possibility : $p(\theta) = Unif(0, 1)$</p></li><li><p>Second, apply Bayes&rsquo; Rule:
$$
\begin{aligned}
p(\theta \vert y) &\propto p(y \vert \theta) p(\theta) \
& = \binom{n}{y} \theta^y (1 - \theta)^{n-y} \
& \propto c \theta^y (1-\theta)^{n-y}
\end{aligned}
$$</p><ol><li>Find $c$ using definition
$$\int_0^1 c \theta^y (1 - \theta)^{n-y} d \theta = 1$$
$$\Rightarrow c = \frac{1}{\int_0^1 \theta^y (1-\theta)^{n-y} d \theta} = \frac{1}{p(y)}$$</li><li>Find $c$ using known distribution
$$\theta^{(y + 1) - 1} (1- \theta)^{(n - y + 1) - 1} \sim Beta(y + 1, n - y + 1)$$</li></ol><ul><li>So, the posterior distribution $Beta(y + 1, n - y + 1)$</li></ul></li><li><p>Posterior mean
$$
\begin{aligned}
E[\theta \vert y] &= \int_0^1 \theta p(\theta \vert y) d \theta \
& = \frac{n}{n+2} (\frac{y}{n}) + \frac{2}{n+2} (\frac{1}{2}) \
& = \frac{n}{n+2} (\text{sample mean from data}) + \frac{2}{n+2} (\text{prior mean})
\end{aligned}
$$
$\Rightarrow$ Posterior mean is the weighted average of MLE & prior
$n \uparrow \Rightarrow E[\theta \vert y] \rightarrow MLE$
$n \downarrow \Rightarrow E[\theta \vert y] \rightarrow \text{prior mean}$</p></li></ul><h2 id=binomial-model-with-beta-prior-1>Binomial Model with Beta Prior</h2><ul><li><p>Use the different prior distribution:
$$p(\theta) = Beta(\alpha, \beta)$$</p></li><li><p>Posetrior distribution:
$$\begin{aligned}
p(\theta \vert y) &\propto p(y \vert \theta) p(\theta) \
& \propto \theta^{y + \alpha - 1} (1- \theta)^{n-y + \beta +1} \
& \sim Beta(y + \alpha, n - y + \beta)
\end{aligned}$$
$$\Rightarrow p(\theta \vert y) = \frac{\Gamma(n + \alpha + \beta)}{\Gamma(y + \alpha) \Gamma(n - y + \beta)} \theta^{y + \alpha - 1} (1- \theta)^{n - y + \beta + 1}$$</p></li><li><p>Posterior Mean:
$$ \begin{aligned} E[\theta \vert y] & = \frac{y + \alpha}{n + \alpha + \beta} \ &= \frac{n}{n+\alpha + \beta} (\frac{y}{\alpha}) + \frac{\alpha + \beta}{n + \alpha + \beta}(\frac{\alpha}{\alpha + \beta}) \
& = \frac{n}{n+\alpha+\beta} (\hat \theta_{MLE}) + \frac{\alpha + \beta}{n + \alpha + \beta} E[\theta] \end{aligned}$$
$\Rightarrow$ Weighted average of sample mean & prior mean</p></li><li><p>$$n \uparrow \Rightarrow E[\theta \vert y] \rightarrow \bar y$$</p></li><li><p>$$n \downarrow \Rightarrow E[\theta \vert y] \rightarrow \text{ prior mean }$$</p></li><li><p>$(\alpha + \beta)$ : amount of prior information</p><ul><li>$$(\alpha + \beta) \uparrow \Rightarrow E[\theta \vert y] \rightarrow \text{ prior mean } E[\theta]$$</li></ul></li><li><p>What is the 95% posterior interval?</p><ol><li>Find $a$, $b$ satisfying $\int_a^b p(\theta \vert y) d \theta = 0.95$</li><li>Normal aaproximation</li><li>Numerical method(quantile-based C.I)</li><li>HPD(Highetst Posterior Density) Interval</li></ol></li></ul><h1 id=posterior-predictive-distribution-1>Posterior Predictive Distribution</h1><h2 id=posterior-predictive-distribution-2>Posterior Predictive Distribution</h2><ul><li>After the data y have been observed, we can predict an unknown observable $\tilde y$</li><li>The posterior predictive distribution of a future observation, $\tilde y$ is
$$\begin{aligned}
p(\tilde y \vert y) &= \int p(\tilde y, \theta \vert y) d \theta \
&= \int p(\tilde y \vert \theta, y) p(\theta \vert y) d \theta \
&= \int p(\tilde y \vert \theta) p(\theta \vert y) d \theta
\end{aligned}$$</li><li>Assumed $y$ and $\tilde y$ are conditional independent given $\theta$</li><li>prior predictive distribution function before $y$ observed
$$\begin{aligned}
p(\tilde y) &= \int p(\tilde, \theta) d \theta \
&= \int p(\tilde y \vert \theta) p(\theta) d \theta
\end{aligned}$$</li></ul><h1 id=poisson-model>Poisson Model</h1><h2 id=poisson-model-1>Poisson Model</h2><ul><li>Data model: $y_i \overset{iid}{\sim} Poison(\theta)$, $i=1,&mldr;,n$</li><li>Prior distribution : $\theta \sim Gamma(\alpha, \beta)$</li><li>Posterior distribution of $\theta$ given $y$</li><li>$L(\theta) = \prod_{i=1}^n \frac{1}{y_i!}\theta^{y_i} e^{-\theta} = (\prod_{i=1}^n \frac{1}{y_i!}) \theta^{\sum y_i} e^{-n\theta}$</li><li>MLE for $\theta$:
$$\frac{\partial log L}{\partial \theta} = \frac{\sum y_i}{\theta} - n = 0$$
$$\Rightarrow \hat \theta_{ML} = \frac{1}{n} \sum y_i = \bar y$$</li></ul><p>$$
\begin{aligned}
p(\theta \vert y) & \propto p(y \vert \theta) p(\theta) \
& \propto e^{\sum y_i + \alpha - 1} e^{-(n + \frac{1}{\beta}) \theta} \
& \sim Gamma(\sum y_i + \alpha, [n + \frac{1}{\beta}]^{-1})
\end{aligned}
$$</p><ul><li>Posterior Mean
$$
\begin{aligned}
E[\theta \vert y] &= \frac{n}{n + \frac{1}{\beta}} (\frac{\sum y_i}{n}) + \frac{\frac{1}{\beta}}{n + \frac{1}{\beta}} (\alpha \beta) \
&= \frac{n}{n + \frac{1}{\beta}} (\hat \theta_{ML}) + \frac{\frac{1}{\beta}}{n + \frac{1}{\beta}} (E[\theta]) \
\end{aligned}
$$</li><li>$$n \uparrow \Rightarrow E[\theta \vert y] \rightarrow \hat \theta_{ML}$$</li><li>$$n \downarrow \Rightarrow E[\theta \vert y] \rightarrow \alpha \beta (\text{ prior mean} )$$</li></ul><h2 id=posterior-predictive-distribution-of-poisson-model>Posterior Predictive Distribution of Poisson Model</h2><ul><li>Posterior predictive distribution, $p(\tilde y \vert y)$:
$$
\begin{aligned}
p(\tilde y \vert y_1, &mldr;, y_n) &= \int_0^\infty p(\tilde y \vert \theta) p(\theta \vert y_1, &mldr;, y_n) d \theta \
& = \frac{\Gamma(\tilde y + \sum y_i + \alpha)}{\Gamma(\sum y_i + \alpha) \tilde y!} (\frac{n + \frac{1}{\beta}}{n + \frac{1}{\beta} + 1})^{\sum y_i + \alpha} (\frac{1}{n + \frac{1}{\beta} + 1})^{\tilde y} \
& \Rightarrow \tilde y \vert y \sim NegBin(\sum y_i + \alpha, \frac{n + \frac{1}{\beta}}{n + \frac{1}{\beta} + 1})
\end{aligned}
$$</li></ul><h1 id=normal-model>Normal Model</h1><ul><li>Normal model with unknown mean $\theta$ and known variance $\sigma^2$
$$ y \sim N(\theta, \sigma^2)$$</li><li>Prior distribution : $\theta \sim N (\mu, \tau^2)$</li><li>Posterior distribution of $\theta$ given $y$
$$
\begin{aligned}
p(\theta \vert y) & \propto p(y \vert \theta) p(\theta) \
& \propto exp[- \frac{1}{2} (\frac{1}{\sigma^2} + \frac{1}{\tau^2}) (\theta - \frac{\frac{y}{\sigma^2} + \frac{\mu}{\tau^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}})^2]
\end{aligned}
$$
$$ \theta \vert y \sim N(\frac{\frac{y}{\sigma^2} + \frac{\mu}{\tau^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}}, [\frac{1}{\sigma^2 } + \frac{1}{\tau^2}]^{-1})$$</li><li>Posterior Mean
$$ \begin{aligned}
E[\theta \vert y] & = \frac{\frac{1}{\sigma^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}} y + \frac{\frac{1}{\tau^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}} \mu \
& = \frac{\frac{1}{\sigma^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}} \hat \theta_{ML} + \frac{\frac{1}{\tau^2}}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}} E[\theta] \
\end{aligned}
$$<ul><li>$\tau^2$ : prior variance<ul><li>$$\tau^2 \uparrow \Rightarrow \text{ Little Information } \Rightarrow E[\theta \vert y] \rightarrow y (\text{sample mean})$$</li><li>$$\tau^2 \downarrow \Rightarrow \text{ Much information } \Rightarrow E[\theta \vert y] \rightarrow \mu$$</li></ul></li></ul></li><li>Posterior Varaince : $[\frac{1}{\sigma^2} + \frac{1}{\tau^2}]^{-1}$<ul><li>$\text{precision} = \frac{1}{\text{variance}}$</li><li>$\frac{1}{\sigma^2}$ : precision of data model</li><li>$\frac{1}{\tau^2}$ : precision of prior</li><li>posterior precision = prior precision + data precision</li></ul></li></ul><h2 id=normal-model-with-multiple-observations>Normal Model with Multiple Observations</h2><ul><li><p>Normal model with unknown mean $\theta$ and known variance $\sigma^2$
$$ \begin{aligned} y_i &\overset{iid}{\sim} N(\theta, \sigma^2), & i=1,&mldr;,n \end{aligned}$$</p></li><li><p>Prior distribution : $\theta \sim N(\mu, \tau^2)$</p></li><li><p>Posterior distribution of $\theta$ given $y_1, &mldr;, y_n$
$$
\begin{aligned}
p(\theta \vert y) & \propto p(y \vert \theta) p(\theta) \
& \propto exp[-\frac{1}{2} (\frac{n}{\sigma^2} + \frac{1}{\tau^2})(\theta - \frac{\frac{\sum y_i}{\sigma^2} + \frac{\mu}{\tau^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}})^2] \
\end{aligned}
$$
$$\Rightarrow \theta \vert y \sim N(\frac{\frac{\sum y_i}{\sigma^2} + \frac{\mu}{\tau^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}}, [\frac{n}{\sigma^2} + \frac{1}{\tau^2}]^{-1})$$</p></li><li><p>Posterior Mean
$$ \begin{aligned}
E[\theta \vert y] & = \frac{\frac{n}{\sigma^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}} (\frac{\sum y_i}{n}) + \frac{\frac{1}{\tau^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}} \mu \
& = \frac{\frac{n}{\sigma^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}} \hat \theta_{ML} + \frac{\frac{1}{\tau^2}}{\frac{n}{\sigma^2} + \frac{1}{\tau^2}} E[\theta] \
\end{aligned}
$$</p><ul><li>$\tau^2$ : prior variance<ul><li>$$\tau^2 \uparrow \Rightarrow \text{ Little Information } \Rightarrow E[\theta \vert y] \rightarrow \bar y (\text{sample mean})$$</li><li>$$\tau^2 \downarrow \Rightarrow \text{ Much information } \Rightarrow E[\theta \vert y] \rightarrow \mu$$</li></ul></li></ul></li><li><p>Posterior Varaince : $[\frac{n}{\sigma^2} + \frac{1}{\tau^2}]^{-1}$</p><ul><li>$\text{precision} = \frac{1}{\text{variance}}$</li><li>$\frac{n}{\sigma^2}$ : precision of data model</li><li>$\frac{1}{\tau^2}$ : precision of prior</li><li>posterior precision = prior precision + data precision</li></ul></li></ul><h2 id=posterior-predictive-distribution-3>Posterior Predictive Distribution</h2><ul><li>Normal model with unknown mean $\theta$ and known variance $\sigma^2$
$$ \begin{aligned} y_i &\overset{iid}{\sim} N(\theta, \sigma^2), & i=1,&mldr;,n \end{aligned}$$</li><li>Prior distribution : $\theta \sim N(\mu, \tau^2)$</li><li>Posterior predictive distribution, $p(\tilde y \vert y)$
$$
\begin{aligned}
p(\tilde y \vert y) &= \int_{- \infty}^{\infty} p(\tilde y \vert \theta) p(\theta \vert y) d \theta \
& \propto \int exp[-\frac{1}{2} (\frac{1}{\sigma^2} + \frac{1}{\tau^2}) \theta^2 d\theta] \times exp[- \frac{1}{2\sigma^2} \tilde y^2] \
& \propto exp [- \frac{1}{2} \frac{1}{\sigma^2 + \tau^2}(\tilde y - \mu)^2]
\end{aligned}
$$
$\Rightarrow \tilde y \vert y \sim N(\mu, \sigma^2 + \tau^2)$</li></ul><h2 id=normal-model-with-known-mean-and-unknown-variance>Normal Model with Known Mean and Unknown Variance</h2><ul><li>Normal model with known mean $\theta$ and unknown variance $\sigma^2$.
$$\begin{aligned} y_i &\sim N(\theta, \sigma^2),& i = 1, &mldr;, n \end{aligned}$$</li><li>Prior distribution : $\sigma^2 \sim Inverse-Gamma(\alpha, \beta)$</li><li>cf. Inverse-Gamma distribution
$$ x \sim Inverse-Gamma(\alpha, \beta)$$
where $\alpha > 0$ (shape), $\beta > 0$(shape), and $x \in (0, \infty)$<ul><li>Density function
$$ p(x) = \frac{1}{\Gamma(\alpha) \beta^{-\alpha}} x^{-(\alpha + 1)} e^{- \frac{\beta}{x}}$$</li></ul></li><li>Posterior distribution of $\sigma^2$ given $y_1, &mldr;, y_n$
$$
\begin{aligned}
p(\sigma^2 \vert y) & \propto p(y \vert \sigma^2) p(\sigma^2) \
& \propto (\sigma^2)^{- (\frac{n}{2} + \alpha + 1)} e^{- \frac{1}{\sigma^2} (\frac{1}{2} \sum(y_i - \theta)^2 + \beta)} \
& \sim Inverse-Gamma(\frac{n}{2} + \alpha, \frac{1}{2} \sum (y_i - \theta)^2 + \beta)
\end{aligned}
$$</li></ul><h1 id=conjugate-families>Conjugate Families</h1><ul><li>Definition : If $F$ is a class of sampling distribution $p(y \vert \theta)$, and $P$ is a class of prior distributions for $\theta$, then the class $P$ is conjugate for $F$ if
$$ p(\theta \vert y) \in P \text{ for all } p(\cdot \vert \theta) \in F \text{ and } p(\cdot) \in P$$</li><li>Conjugate Families<table><thead><tr><th>Data Model $p(y \vert \theta)$</th><th>Conjugate Distribution</th></tr></thead><tbody><tr><td>Binomial / Bernoulli</td><td>Beta</td></tr><tr><td>Poisson</td><td>Gamma</td></tr><tr><td>Normal (unknown mean)</td><td>Normal</td></tr><tr><td>Normal (unknown variance)</td><td>Inverse Gamma</td></tr><tr><td>Gamma</td><td>Gamma</td></tr></tbody></table></li></ul><h1 id=prior-distributions>Prior Distributions</h1><h2 id=noninformative-prior-distributions>Noninformative Prior Distributions</h2><ul><li>When a prior does not depend on the data and does not affect the posterior distribution, the prior density is described as vague, flat, diffuse or noninformative.</li><li>&ldquo;Let the data speak for themselves&rdquo; so that inferences are unaffected by information external to the current data.</li></ul><h2 id=informative-prior-distributions>Informative Prior Distributions</h2><ul><li>A prior distribution is informative if the hyperparameters are chosen to reflect a priori (before seeing the data) knowledge about the known parameters.</li><li>A prior distribution is weakly informative if it contains some information-enough to keep it rougly within reasonable bounds-but without attempting to fully capture one&rsquo;s scientific knowledge about the underlying parameters.</li></ul><h2 id=proper--improper-prior-distributions>Proper / Improper Prior Distributions</h2><ul><li>A prior distribution is proper if it does not depend on the data and it integrates to 1.</li><li>A prior distribution is improper if the distribution does not integrate to 1.<ul><li>Ex) $x_1, &mldr;, x_n \sim N(\theta, 1)$ and $p(\theta) = c (constant)$</li><li>$\rightarrow \int_{-\infty}^{\infty} p(\theta) d \theta = \infty$</li></ul></li><li>Can we use improper prior distributions in Bayesian modeling?<ul><li>Yes, because improper prior distributions can lead to proper posterior distributions.</li></ul></li><li>If we specify a noninformative prior using an improper distribution, then we must show analytically that our posterior distribution is proper.</li></ul><h1 id=jeffreys-prior>Jeffreys&rsquo; Prior</h1><h2 id=lack-of-invariance>Lack of Invariance</h2><ul><li>Consider a normal model with known mean $\mu$ and unknown variance $\theta$:
$$\begin{aligned} y_i & \sim N(\mu, \theta), & i = 1,&mldr;, n \end{aligned}$$</li><li>Because $\theta \in (0, \infty)$, let $\phi = log \theta$ and then $\phi \in (-\infty, \infty)$</li><li>A noninformative prior implies that
$$ p(\phi) \propto 1 \Rightarrow p(\theta) = p(\phi) \vert \frac{d \phi}{d \theta} \vert \propto \frac{1}{\theta}$$
which is no longer flat.</li><li>Criticized for the lack of invarinace under one-to-one transformations.</li></ul><h2 id=jeffreys-noninformative-prior>Jeffreys&rsquo; Noninformative Prior</h2><ul><li>Jeffreys&rsquo; general principle : any rule for determining the prior density $p(\theta)$ should yield an equivalent result if applied to the transformed parameter: $\phi = h(\theta)$</li><li>Jeffreys&rsquo; prior is given by<ul><li>$$ p(\theta) \propto \sqrt{I(\theta)}$$</li><li>where $I(\theta)$ is the Fisher Information for $\theta$:
$$ I(\theta) = - E[\frac{\partial^2 log p(y \vert \theta)}{\partial \theta^2} \vert \theta]$$</li></ul></li><li>To see that Jeffreys&rsquo; prior model is invariant to parameterization, we derive a prior for $\phi = h(\theta)$
$$\begin{aligned} p(\phi) &= p(\theta) \vert \frac{d \theta}{d \phi} \vert \
&\propto \sqrt{I(\theta)} \sqrt{(\frac{d\theta}{d\phi})^2} \
&= \sqrt {E[(\frac{\partial log L}{\partial \theta})^2] (\frac{d \theta}{d\phi})^2} \
&= \sqrt{E[(\frac{\partial log L}{\partial \theta} \frac{d \theta}{d \phi})^2 \vert \phi]} \
&= \sqrt{E[(\frac{d log L}{d\phi})^2 \vert \phi]} \
&= \sqrt{I(\phi)} \end{aligned}$$</li></ul><h1 id=bayesian-inference>Bayesian Inference</h1><h2 id=point-estimation>Point Estimation</h2><ul><li>From a Bayesian perspective, point estimation means that we would use a single statistic to summarize the posterior distribution, $p(\theta \vert y)$. The most important number summarizing a distribution would be its location.</li><li>Posterior Mean<ul><li>$\hat \theta = E[\theta \vert y] = \int \theta p(\theta \vert y) d \theta$</li></ul></li><li>Posterior Median<ul><li>$\hat \theta: \int_{-\infty}^{\hat \theta} p(\theta \vert y) d \theta = 0.5$</li></ul></li><li>Posterior Mode (= Maximum a Posteriori (MAP) estimate)<ul><li>$\hat \theta = \underset{\theta}{argmax} p(\theta \vert y)$</li><li>Under $p(\theta) \propto 1$, the posterior mode is the MLE.</li></ul></li><li>The most common classical technique to estimate $\theta$ is maximum likelihood estimation(MLE), which can be applied to the osterior distribution.</li><li>Definition : The generalized maximum likelihood estimate of $\theta$ is the largest mode of $p(\theta \vert y)$, i.e., the value $\hat \theta$ which maximizes $p(\theta \vert y)$.</li><li>Obviously, $\hat \theta$ has the interpretation of being the &ldquo;most likely&rdquo; value of $\theta$, given the prior and the sample $y$.</li><li>It is probably worthwhile to calculate and compare all three in a Bayesian study.</li></ul><h2 id=frequentist-criteria-for-evaluating-estimators>Frequentist Criteria for Evaluating Estimators</h2><ul><li><p>Unbiased Estimators : An estimator is said to be unbiased if the mean of its sampling distribution is the true parameter value. That is, an estimator $\hat \theta$ is unbaised if and only if
$$ E[\hat \theta] = \in \hat \theta f(\hat \theta \vert \theta) d \hat \theta = \theta$$
where $f(\hat \theta \vert \theta)$ is the sampling distribution of the estimator $\hat \theta$ given the parameter $\theta$.</p></li><li><p>Minimum Variance Unbaised Estimator : AN estimator is said to be a minimum variance unbiased estimator if no other unbiased estimator has a smaller variance. Minimum variance unbiased estimators are often considered the best estimators in frequentist statistics.</p></li><li><p>Mean Squared Error of an Estimator : The MSE is the average squared distance the estimator is away from the true value.
$$ \begin{aligned} MSE[\hat \theta] &= E[\hat \theta - \theta]^2 = \in (\hat \theta - \theta)^2 f(\hat \theta \vert \theta) d \hat \theta \
&= Bias[\hat \theta, \theta]^2 + Var[\hat \theta]\end{aligned}$$</p><h2 id=comparing-estimators-for-proportion>Comparing Estimators for Proportion</h2><ul><li>When judged by the frequentist criterion of mean squared error.</li><li>Example<ul><li>$Y \sim Bin(n, \theta)$</li><li>$\hat \theta_{ML} = \frac{y}{n}$<ul><li>$E[\hat \theta_{ML}] = \theta$ : Unbiased</li><li>$Var(\hat \theta_{ML}) = \frac{\theta (1 - \theta)}{n}$<ul><li>$\Rightarrow MSE[\hat \theta_{ML}] = \frac{\theta (1-\theta)}{n}$</li></ul></li></ul></li><li>$\hat \theta_B = \frac{y+1}{n+2}$<ul><li>$E[\hat \theta_B] = \frac{n\theta +1}{n+2} \Rightarrow Bias = \frac{n \theta + 1}{n + 2} - \theta$</li><li>$Var(\hat \theta_B) = \frac{n \theta(1 - \theta)}{(n + 2)^2}$</li><li>$MSE[\hat \theta_B] = \frac{(4 - n) \theta^2 - (4 - n)\theta + 1}{(n + 2)^2}$</li></ul></li><li>Sample Size가 작을때는 $\theta$가 0또는 1에 아주 가까운 값이 아니라면 Bayesian이 우세하다.</li><li>Sample Size가 커져도 $\theta$가 0.5에 가까우면 베이지안 추정이 우세하게 되고, 그렇지 않더라도 거의 비슷하다.</li></ul></li></ul></li></ul><h2 id=posterior-mse>Posterior MSE</h2><ul><li>WHen presenting a statistical estimate, it is usually necessary to indicate the accuracy of the estimate</li><li>$\delta(y)$ : an estimate of parameter $\theta$</li><li>Posterior Mean Squared Error (MSE) of $\delta(y)$:
$$\begin{aligned} V_\delta (y) &= E { [\theta - \delta(y)]^2 \vert y} \ &= Var(\theta \vert y) + [E(\theta \vert y) - \delta(y)]^2 \end{aligned}$$
$$\begin{aligned}
pMSE &= (\delta(y) - \theta)^2 \vert y] \
&= E[\delta(y - E[\theta \vert y] + E[\theta \vert y] - \theta)^2 \vert y] \
& = E[(\delta(y) - E[\theta \vert y])^2 \vert y] + E[(\theta - E[\theta \vert y])^2 \vert y] + \underset{=0}{E[2(\delta(y) - E[\theta \vert y])(E[\theta \vert y] - \theta) \vert y]}\
& = (\delta(y) - E[\theta \vert y])^2 + Var(\theta \vert y) \ge Var(\theta \vert y)
\end{aligned}$$</li><li>If $\delta(y) = E[\theta \vert y]$, then posterior MSE = posterior Variance. So p mean smallest pMSE!</li></ul><h1 id=confidence-regions>Confidence Regions</h1><h2 id=frequentist-confidence-interval>Frequentist Confidence Interval</h2><ul><li>A $(1 - \alpha) \times 100$% confidence interval for a parameter $\theta$ is an interval $(l, u)$ such that
$$ P(l \le \theta \le u) = 1 - \alpha$$</li><li>The endpoints $l$ and $u$ are random variables since they depend on the random sample.</li><li>Under the frequentist paradigm, the correct interpretation is that $(1 - \alpha) \times 100$% of the random intervals calculated this way will contain the true value.</li><li>Often, the sampling distribution of the estimator used is approximately normal. For example, if $n$ is large in the binomial model, the sample proportion $\hat \theta_f = \frac{y}{n}$ is approximately normal with $\theta$ and standard deviation $\sqrt \frac{\theta(1 - \theta)}{n}$</li><li>This gives an approximate $(1 - \alpha) \times 100$% equal tail area confidence interval for $\theta$:
$$ \hat \theta_f \pm z_{\alpha /2} \times \sqrt {\frac{\hat \theta_f (1 -\hat \theta_f)}{n}}$$</li></ul><h2 id=bayesian-credible-interval>Bayesian Credible Interval</h2><ul><li><p>A $(1 - \alpha) \times 100$ % Bayesian credible interval is an interval that has a posterior probability of $1 - \alpha$ of containing the parameter:
$$ P(l \le \theta \le u \vert y) = \int_l^u p(\theta \vert y) d \theta = 1 - \alpha$$</p></li><li><p>Equal tail area Bayesian credible intervals are often used, since they are easy to find.</p></li><li><p>Quantile-based interval : to make a $(1 - \alpha) \times 100$% quantile-based confidence interval, find numbers $\theta_{\alpha/2} &lt; \theta_{1 - \alpha /2}$ such that:</p><ol><li>$P(\theta &lt; \theta_{\alpha / 2} \vert Y = y) = \alpha / 2$</li><li>$P(\theta > \theta_{1 - \alpha /2} \vert Y = y) = \alpha /2$</li></ol><ul><li>So,
$$P(\theta_{\alpha / 2} \le \theta \le \theta_{1 - \alpha / 2} \vert Y = y) = 1 - \alpha$$</li></ul></li><li><p>Approximation Method</p><ol><li>Simulation method:</li></ol><ul><li>draw 1000 samples from $p(\theta \vert y)$</li><li>find 25th, 975th values $\Rightarrow$ lower bound, upper bound</li></ul><ol start=2><li>Normal approximation:</li></ol><ul><li>using $E[\theta \vert y]$ & $SD[\theta \vert y]$ $\rightarrow$ useful for symmetric distribution</li></ul></li></ul><h2 id=highest-posterior-density-hpd-credible-set>Highest Posterior Density (HPD) Credible Set</h2><ul><li>The $100(1 - \alpha)$ % Highest Posterior Density (HPD) credible set for $\theta$ is the subset $C$ of $\Theta$ of the form
$$ C = {\theta \in \Theta : p(\theta \vert y) \ge k(\alpha) }$$<ul><li>where $k(\alpha)$ is a constant such that
$$P(\theta \in C \vert y) = 1 - \alpha$$</li></ul></li><li>All points in an HPD region have a higer posterior density than points outside the region.</li></ul><h1 id=hypothesis-testing>Hypothesis Testing</h1><h2 id=classical-p-values>Classical P-values</h2><ul><li>Let $y$ be the observed data and $\theta$ be the vector of parameters, and $y^{rep}$ be the replicated data that could have been observed under the same model and the same value of $\theta$ that produced the observed data.</li><li>The classical p-value for the test statistic $T(y)$ is
$$p_c = P{ T(y^{rep}) \text{ more &ldquo;extreme&rdquo; than } T(y) \vert \theta, H_0 }$$
where the probability is taken over the distribution of $y$ with $\theta$ fixed, and &ldquo;extremeness&rdquo; is in the direction of the alternative hypothesis.</li><li>If the p-value is less than some prespecified Type I error rate, $H_0$ is rejected; otherwise, it is not.</li></ul><h2 id=posterior-predictive-p-values>Posterior Predictive P-values</h2><ul><li><p>To evaluate the fit of the posterior distribution of a Bayesian model, we can compare the observed data to the posterior predictive distribution.</p></li><li><p>The Bayesian p-value is defined as the probability that the replicated data could be more extreme than the observed data, as measured by the test quantity:
$$p_B = P(T(y^{rep}, \theta) \ge T(y, \theta) \vert y)$$</p></li><li><p>It works with the distribution of $y^{rep}$ given the current state of knowledge, that is, with the posterior predictive distribution,
$$p(y^{rep} \vert y) = \int p(y^{rep} \vert \theta) p(\theta \vert y) d\theta$$</p></li><li><p>It follows that
$$ p_B = \int \int I_{T(y^{rep}, \theta) \ge T(y, \theta)} p(y^{rep} \vert \theta)p(\theta \vert y) d y^{rep} d \theta$$</p></li><li><p>In practice, we compute the posterior predictive distribution using simulation.</p></li><li><p>If we already have $S$ simulations from the posterior density of $\theta$, we just draw one $y^{rep}$ from the predictive distribution for each simulated $\theta$. We now have $S$ draws from the joint posterior distribution, $p(y^{rep}, \theta \vert y)$</p></li><li><p>THe posterior predictive check is the comparision between the realized test quantities, $T(y, \theta^s)$, and the predictive test quantities, $T(y^{rep, s}, \theta^s)$</p></li><li><p>The estimated p-value is just the proportion of these $S$ simulations for which the test quantity equals or exceeds it realized value; that is, for which
$$T(y^{rep, s}, \theta^s) \ge T(y, \theta^s), s= 1, &mldr;, S$$</p></li></ul><h1 id=bayes-factor>Bayes Factor</h1><h2 id=bayesian-hypothesis-testing>Bayesian Hypothesis Testing</h2><ul><li>To evaluate the relative plausibility of a hypothesis (model), we use the posterior model probability:
$$ p(H_j \vert y) = \frac{p(y \vert H_j) p(H_j)}{p(y)} \propto p(y \vert H_j) p(H_j)$$
where $p(H_j)$ is the prior model probability and
$$p(y \vert H_j) = \int p(y \vert \theta) p(\theta \vert H_j) d\ theta$$
is the marginal likelihood under model $H_j$ and $p(\theta \vert H_j)$ is the prior for parameter $\theta$ when model $H_j$ is true.</li><li>Note that the marginal likelihood for simple hypotheses, e.g. if $H_0: \theta = \theta_0$ then $\theta \vert H_0 \sim \delta_{\theta_0}$, is
$$ p(y \vert H_0) = \int p(y \vert \theta) p(\theta \vert H_0) d \theta = p(y \vert \theta_0)$$</li></ul><h2 id=bayes-factor-1>Bayes Factor</h2><ul><li>If we only have two models: $H_0$ and $H_1$, then the Bayes Factor is defined as the ratio of the posterior odds of $H_1$ to the prior odss of $H_1$:
$$ \begin{aligned}
BF(H_1 : H_0) & = \frac{p(H_1\vert y) / p(H_0 \vert y)}{p(H_1) / p(H_0)} \
&= \frac{p(y \vert H_1)}{p(y \vert H_0)}
\end{aligned} $$
which is the ratio of the observed marginal densities for the two models.</li><li>Assuming the two models are a prior equally probable (i.e., $p(H_1) = p(H_0) = 0.5$), we have that
$$ BF(H_1: H_0) = \frac{p(H_1 \vert y)}{p(H_0 \vert y)}$$
which is the posterior odds of $H_1$.</li><li>Bayes factor captures the change in the odds in favor of model 1 as we move from prior to posterior.</li></ul><h2 id=probabilities-of-bayes-factor>Probabilities of bayes Factor</h2><ul><li>Bayes factors<ul><li>need proper priors.</li><li>reduce to likelihood ratio for simple hypotheses.</li><li>work also for non-nested models.</li><li>are symmetric measures of evidence.</li></ul></li><li>Clearly a Bayes factor much greater than 1 supports Model 1 over Model 0.</li><li>Kass and Raftery (1995) proposed the following rules:</li></ul><table><thead><tr><th>BF</th><th>Strength of Evidence</th></tr></thead><tbody><tr><td>&lt; 1</td><td>Negative (supports $H_0$)</td></tr><tr><td>1 to 3</td><td>Barely worth mentioning</td></tr><tr><td>3 to 20</td><td>Positive</td></tr><tr><td>20 to 150</td><td>Strong</td></tr><tr><td>> 150</td><td>Very Strong</td></tr></tbody></table><h1 id=multiparameter-models>Multiparameter Models</h1><ul><li>Every practical problem in statistics involves more than one unknown quantity.</li><li>Assume that we have a model with two parameters $\theta_1$ and $\theta_2$. We are interested in the posterior distribution $\theta_1$ given y</li><li>$\theta_2$ may be considered a &ldquo;nuisance&rdquo; parameter</li><li>Joint posterior distribution:
$$ p(\theta_1, \theta_2 \vert y) \propto p(y \vert \theta_1, \theta_2) p(\theta_1, \theta_2)$$</li><li>Marginal posterior distribution:
$$ \begin{aligned} p(\theta_1 \vert y) &= \int p(\theta_1, \theta_2 \vert y) d \theta_2 \ &= \int p(\theta_1 \vert \theta_2, y) p(\theta_2 \vert y) d \theta_2\end{aligned}$$</li></ul><h1 id=normal-with-noninformative-prior>Normal with Noninformative Prior</h1><h2 id=normal-model-with-a-noninformative-prior-distribution>Normal Model with a Noninformative Prior Distribution</h2><ul><li><p>Data model: $\begin{aligned}y_i &\sim N(\mu, \sigma^2), & i=1, &mldr;, n \end{aligned}$</p></li><li><p>Noninformative prior : $p(\mu, \sigma^2) \propto \frac{1}{\sigma^2}$</p></li><li><p>Joint posterior distribution:
$$\begin{aligned}
p(\mu, \sigma^2 \vert y) & \propto \sigma^{-n -2} exp(-\frac{1}{2} \sum_{i=1}^n (y_i - \mu)^2) \
& \propto (\sigma^2) ^{-\frac{n}{2} - 1} exp[- \frac{1}{2 \sigma^2} { (n-1) S^2 + n (\bar y - \mu)^2}]
\end{aligned}$$
where $S^2 = \frac{1}{n-1} \sum (y_i - \bar y)^2$ : sample variance</p></li><li><p>Marginal posterior distribution of $\mu$
$$
\begin{aligned}
p(\mu \vert y) &= \int_0^\infty p(\mu, \sigma^2 \vert y) d \sigma^2 \
& \propto [(n-1)S^2 + n(\bar y - \mu)^2]^{-\frac{n}{2}} \
& \propto [1 + \frac{n (\mu - \bar y)^2}{(n-1)S^2}]^{-\frac{n}{2}} \
& \sim t_{n-1} (\bar y, \frac{\sigma^2}{n}) : \text{ non-standardized t- distribution}
\end{aligned}
$$</p></li><li><p>Marginal posterior distribution of $\sigma^2$
$$\begin{aligned}
p(\sigma^2 \vert y) & \propto \int \sigma^{-n-2} exp(-\frac{1}{2\sigma^2} [(n-1)s^2 + n(\bar - \mu)^2]) d\mu \
& \propto (\sigma^2)^{- \frac{n+1}{2}} exp[- \frac{(n-1)s^2}{2 \sigma^2}] \
& \sim IG(\frac{n-1}{2}, \frac{(n-1)s^2}{2}) = \text{ (scaled) Inverse } \chi^2(n-1, s^2)
\end{aligned}$$</p></li><li><p>Conditional posterior distribution of $\mu$
$$\begin{aligned}
p(\mu \vert \sigma^2, y) & \propto p(y \vert \mu, \sigma^2) p(\mu \vert \sigma^2) \
& \propto \prod_{i=1}^n e^{-\frac{1}{2\sigma^2} (y_i - \mu)^2} \
& \sim N(\bar y, \frac{\sigma^2}{n})
\end{aligned}$$</p></li><li><p>Conditional posterior distribution of $\sigma^2$
$$\begin{aligned}
p(\sigma^2 \vert \mu, y) & \propto p(y \vert \mu, \sigma^2) p(\sigma^2 \vert \mu) \
& \propto (\sigma^2)^{-\frac{n}{2} - 1} e^{-\frac{1}{2\sigma^2} \sum(y_i - \mu)^2} \
& \sim IG(\frac{n}{2}, \frac{1}{2} \sum_{i=1}^n (y_i - \mu)^2)
\end{aligned}$$</p></li><li><p>Simulating from the joint posterior distribution</p><ol><li>Independent Simulation</li></ol><pre tabindex=0><code>for (j in 1 :J) {
  - draw \sigma_j^2 from p(\sigma^2 \vert y)
  - draw \mu_j from p(\mu \vert y)
}
</code></pre><ol start=2><li>Conditional simulation</li></ol><pre tabindex=0><code>for (j in 1 :J) {
  - draw \sigma_j^2 from p(\sigma^2 \vert y)
  - draw \mu_j from p(\mu \vert \sigma_j^2, y)
}
</code></pre></li><li><p>Posterior predictive distribution for a future observation
$$ \begin{aligned}
p(\tilde y \vert y) & = \int \int p(\tilde \vert \mu, \sigma^2, y) p(\mu, \sigma^2 \vert y) d \mu d \sigma^2 \
& \sim t_{n-1}(\bar y, (1 + \frac{1}{n})^{\frac{1}{2}} s)
\end{aligned}$$</p></li></ul><h1 id=multinomial-model>Multinomial Model</h1><h2 id=multinomial-model-for-categorical-data>Multinomial Model for Categorical Data</h2><ul><li>Binomial distribution can be generalized to allow more than two possible outcomes.</li><li>Multinomial data : data for which each observation is one of k possible outcomes.</li><li>Multinomial sampling distribution If $y$ is the vector of counts of the number of observations of each outcome, then
$$ p(y \vert \theta) \propto \prod_{j=1}^k \theta_j^{y_i}$$
where $\sum_{j=1}^k \theta_j = 1$ and $\sum_{j=1}^k y_j = n$</li><li>Conjugate prior distribution : Dirichlet distribution</li></ul><h2 id=dirichlet-distribuiton>Dirichlet Distribuiton</h2><ul><li>Dirichlet distribution is a multivariate generalization of the Beta distribution.
$$ \theta \sim Dirichlet(\alpha_1, &mldr;, \alpha_k)$$
where $\alpha_j > 0$ and $\alpha_0 \equiv \sum_{j=1}^k \alpha_j$<ul><li>Density function
$$ p(\theta) = \frac{\Gamma(\alpha_1 + \cdots + \alpha_k)}{\Gamma(\alpha_1) \cdots \Gamma(\alpha_k)} \theta_1^{\alpha_1 - 1} \cdots \theta_k ^{\alpha_k - 1}$$
where $\theta_j \in [0,1]$ and $\sum_{j=1}^k \theta_j = 1$</li><li>Mean and Variance
$$E(\theta_j) = \frac{\alpha_j}{\alpha_0}$$
$$Var(\theta_j) = \frac{\alpha_j(\alpha_0 - \alpha_j)}{\alpha_0^2 (\alpha + 1)}$$
$$Cov(\theta_i, \theta_j) = - \frac{\alpha_i \alpha_j}{\alpha_0^2 (\alpha_0 + 1)}$$</li></ul></li><li>Posterior distribution
$$p(\theta \vert y) \sim Dirichlet (y_1 + \alpha_1, y_2 + \alpha_2, \cdots, y_k + \alpha_k)$$</li></ul><h1 id=multivariate-normal-models>Multivariate Normal Models</h1><h2 id=multivariate-normal-model-with-known-variance>Multivariate Normal Model with Known Variance</h2><ul><li>The baisc model considers an observable vector $y$ of $d$ components, with the multivariate normal distribution,
$$y \vert \mu, \Sigma \sim N(\mu, \Sigma)$$
where $\mu$ is a vector of length $d$ and $\Sigma$ is a $d \times d$ variance matrix, which is symmetric and positive definite.</li><li>The likelihood function for a sample of n iid observations, $y_1, &mldr;, y_n$ is
$$\begin{aligned}
p(y_1, &mldr;, y_n \vert \mu, \Sigma) & \propto \vert \Sigma \vert ^{-n /2} exp(-\frac{1}{2} \sum_{i=1}^n(y_i - \mu)^T \Sigma^{-1} (y_i - \mu)) \
& = \vert \Sigma \vert ^{-n /2} exp(-\frac{1}{2} tr(\Sigma^{-1} S_0))
\end{aligned}$$
where $S_0$ is the matrix of &lsquo;sums of squares&rsquo; relative to $\mu$,
$$S_0 = \sum_{i=1}^n(y_i - \mu)(y_i - \mu)^T$$</li></ul><h2 id=conjugate-analysis>Conjugate Analysis</h2><ul><li>The log-likelihood is a quadratic form in $\mu$, and therefore the conjugate prior distribution for $\mu$ is the multivariate normal distribution, $\mu \sim N(\mu_0, \Lambda_0)$.</li><li>Posterior distribution for $\mu$ is
$$ \mu \vert y, \Sigma \sim N(\mu_n, \Lambda_n)$$
where
$$\mu_n = (\Lambda_0^{-1} + n \Sigma^{-1})^{-1} (\Lambda_0^{-1} \mu_0 + n \Sigma^{-1} \bar y)$$
$$\Lambda_n = (\Lambda_0^{-1} + n \Sigma^{-1})^{-1}$$</li><li>$$\Rightarrow \mu \vert MVN(\mu_n, \Lambda_n)$$</li></ul><h2 id=posterior-marginal-and-conditional-distribution-of-subvectors-of-mu>Posterior Marginal and Conditional Distribution of Subvectors of $\mu$</h2><ul><li>It follows that the marginal posterior distribution of a subset of the parameters, $\mu^{(1)}$ says, is also multivariate normal, with mean vector equal toe the appropriate subvector of the posterior mean vector $\mu_n$ and variance matrix equal to the appropriate submatrix of $\Lambda_n$</li><li>The conditional posterior distribution of a subset $\mu^{(1)}$ given the values of a second subset $\mu^(2)$ is multivariate normal,
$$ \mu^{(1)} \vert \mu ^{(2)}, y \sim N(\mu^{1 \vert 2}, \Lambda^{(1 \vert 2)}$$
where
$$\mu^{1 \vert 2} = \mu_n^{(1)} + \Lambda_n^{(12)} (\Lambda_n^{(22)})^{-1} (\mu^{(2)} - \mu_n ^{(2)})$$
$$\Lambda^{1 \vert 2} = \Lambda_n^{(11)} - \Lambda_n^{(12)} (\Lambda_n^{(22)})^{-1} \Lambda_n^{(21)}$$</li></ul><h2 id=posterior-predictive-distribution-for-new-data>Posterior Predictive Distribution for New Data</h2><ul><li>The joint distribution is the exponential of a quadratic form in $(\tilde y, \mu)$; hence $(\tilde y, \mu)$ have a joint normal posterior distribution, and so the marginal posterior distribution of $\tilde y$ is normal.</li><li>As in the univariate case, we can determine the posterior mean and variance of $\tilde y$
$$p(\tilde y, \mu \vert y) = p(\tilde y \vert \mu) p(\mu \vert y)$$
$$E[\tilde y \vert y] = E[E[\tilde y \vert \mu, y] \vert \mu] = E[\mu \vert y] = \mu_n$$
$$Var(\tilde y \vert y) = E[Var(\tilde y \vert \mu, y) \vert y] + Var[E[\tilde y \vert \mu, y] \vert y] = E[\Sigma \vert y] + Var(\mu \vert y) = \Sigma + \Lambda_n$$</li></ul><h2 id=noninformative-prior-density-for-mu>Noninformative Prior Density for $\mu$</h2><ul><li><p>A noninformative uniform prior density for $\mu$ is
$$ p(\mu) \propto constant$$</p></li><li><p>The posterior density is then proportional to the likelihood. THis is a proper posterior distribution only if $n \ge d$; otherwise the matrix $S_0$ is not full rank.</p></li><li><p>If $n \ge d$, the posterior distribution for $\mu$, given the uniform prior density, is
$$\mu \vert \Sigma, y \sim N(\bar y, \Sigma / n)$$</p></li></ul><p>$$p(\mu \vert y) \propto exp[-\frac{1}{2} (\mu - \bar y)^T n \Sigma^{-1} (\mu - \bar y)]$$</p><h1 id=hierarchical-models>Hierarchical Models</h1><h2 id=hierarchical-models-1>Hierarchical Models</h2><ul><li>For instance, in a study of the effectiveness of cardiac treatments, with the patients in hospital j having survival probability $\theta_j$, it might be reasonable to expect that estimates of the $\theta_j$&rsquo;s, which represent a sample of hosipitals, should be related to each other.<ul><li>Use a prior distribution in which the $\theta_j$&rsquo;s are viewed as a sample from a common population distribution.</li></ul></li><li>The observed data, $y_{ij}$, with units indexed by $i$ within groups indexed by $j$, can be used to estimate aspectes of the population distribution of the $\theta_j$&rsquo;s even though the values of $\theta_j$ are not themselves observed.</li><li>Model hierarchically with observable outcomes modeled conditionally on certain parameters, which themselves are given a probabilistic specification in terms of further parameters, known as hyperparameters.</li></ul><h2 id=general-framework>General Framework</h2><ol><li>Likelihood function:
$$ y_1, &mldr;, y_n \vert \theta_1, &mldr;, \theta_n, \phi \sim p(y_i \vert \theta_i)$$</li><li>Prior distribution:
$$ \theta_1, &mldr;, \theta_n \vert \phi \sim p(\theta_i \vert \phi)$$</li><li>Hyperprior distribution:
$$ \phi \sim p(\phi)$$</li></ol><h2 id=conditional-and-marginal-distributions>Conditional and Marginal Distributions</h2><ul><li>Analytic derivation of condtional and marginal distributions<ol><li>Write the joint posterior density:
$$p(\theta, \phi \vert y) \propto p(y \vert \theta) p(\theta \vert \phi)p(\phi)$$</li><li>Determine analytically the conditional posterior density of $\theta$ given the hyperparameters $\phi$, $p(\theta \vert \phi, y)$.</li><li>Obtain the marginal posterior distribution of $\phi$, $p(\phi \vert y)$.
$$p(\phi \vert y) = \int p(\theta, \phi \vert y) d \theta$$</li></ol></li></ul><h2 id=posterior-summaries>Posterior Summaries</h2><ul><li>Obtaining posterior summaries via conditional simulation<ol><li>Draw the vector of the hyperparameters, $\phi$, from the mgarginal posterior distribution of $\phi$, $p(\phi \vert y)$.</li><li>Draw the parameter vector $\theta$ from its condtional posterior distribution, $p(\theta \vert \phi, y)$, given the drawn value of $\phi$.</li><li>Draw predictive values of $y$ and $\theta$, if desired.</li></ol></li></ul><h1 id=hierarchical-binomial-model>Hierarchical Binomial Model</h1><h2 id=hierarchical-binomial-model-1>Hierarchical Binomial Model</h2><ul><li>Hierarchical Bayeisan Binomial Model:
$$y_1, &mldr;, y_n \vert \theta_1, &mldr;, \theta_n, \alpha, \beta \overset{ind}{\sim} Binomial(n_i, \theta_i)$$
$$\theta_1, &mldr;, \theta_n \vert \alpha, \beta \overset{iid}{\sim} Beta(\alpha, \beta)$$
$$p(\alpha, \beta) \propto 1$$
where $n_i$ are assumed to be known.</li><li>Joint posterior density
$$p(\theta, \alpha, \beta \vert y) \propto [\prod_{i=1}^n \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta_i^{y_i + \alpha - 1} (1 - \theta_i)^{n_i - y_i + \beta +1}]$$</li><li>Conditonal posterior density of $\theta$
$$\begin{aligned}
p(\theta_i \vert \alpha, \beta, \theta_{(-i)}, y) & \propto \theta_i^{y_i + \alpha - 1} (1 - \theta_i)^{n_i - y_i + \beta -1} \
& \sim Beta(y_i + 2, n_i - y_i + \beta)
\end{aligned}$$
$$\begin{aligned}
p(\theta_1, &mldr;, \theta_n \vert \alpha, \beta, y) & \propto \prod_{i=1}^n Beta(y_i + \alpha, n_i - y_i + \beta)
\end{aligned}$$</li><li>Marginal posterior density of $(\alpha, \beta)$
$$p(\alpha, \beta \vert y) \propto \prod_{i=1}^n \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \times \frac{\Gamma(\alpha + y_i) \Gamma(\beta + n_i - y_i)}{\Gamma(\alpha + \beta + n_i)}$$</li><li>Conditional posterior density of $(\alpha, \beta)$
$$p(\alpha, \beta \vert \theta_1, &mldr;, \theta_n, y) \propto \prod_{i=1}^n [\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta_i ^{\alpha - 1}(1 - \theta_i)^{\beta - 1}]$$</li></ul><h1 id=hierarchical-poisson-model>Hierarchical Poisson Model</h1><h2 id=hierarchical-poisson-model-1>Hierarchical Poisson Model</h2><ul><li><p>Hierarchical Bayeisan Binomial Model:
$$y_1, &mldr;, y_n \vert \theta_1, &mldr;, \theta_n, \alpha, \beta \overset{ind}{\sim} Poisson(\lambda_i)$$
$$\lambda_1, &mldr;, \lambda_n \vert \beta \overset{iid}{\sim} Gamma(\alpha, \beta)$$
$$\beta \sim Gamma(c, d)$$
where $\alpha$, $c$, $d$ are assumed to be known.</p></li><li><p>Joint posterior density
$$p(\lambda, \beta \vert y) \propto [ \prod_{i=1}^n (\lambda_i)^{y_i + \alpha - 1} e^{- (1 + \frac{1}{\beta} \lambda_i)}]\beta^{c - 1 - n\alpha} e^{-\frac{\beta}{\alpha}}$$
where $n_i$ are assumed to be known.</p></li><li><p>Conditional posterior density of $\lambda$
$$ p(\lambda_i \vert \beta, \lambda_{(-i)}, y) \sim Gamma(y_i + \alpha, [1 + \frac{1}{\beta}]^{-1})$$
$$ p(\lambda_1, &mldr;, \lambda_n \vert \beta, y) \propto \prod_{i=1}^n \frac{(1 + \frac{1}{\beta})^{y_i + \alpha}}{\Gamma (y_i + \alpha)} \lambda_i^{y_i + \alpha - 1} e^{-(1 +\frac{1}{\beta})}$$</p></li><li><p>Marginal posterior density of $\beta$
$$ \begin{aligned}
p(\beta \vert y) &= \int \cdots \int p(\lambda_1, &mldr;, \lambda_n, \beta \vert y) d \lambda_1 \cdots d \lambda_n \
& = \frac{p(\lambda, \beta \vert y)}{p(\lambda \vert \beta, y)}
\end{aligned}$$</p></li><li><p>Conditional posterior density of $\beta$
$$ \begin{aligned}
p(\beta \vert \lambda, y) & \propto [\prod_{i=1}^n e^{-\frac{1}{\beta} \lambda_i}] \beta^{c - 1 -n\alpha} e^{-\frac{\beta}{\alpha}} \
& = e^{- \frac{1}{\beta} \sum \lambda_i } e^{-\frac{\beta}{\alpha}} \beta^{c - 1 - n \alpha}
\end{aligned}$$</p></li></ul><h2 id=hierarchinal-normal-model>Hierarchinal Normal Model</h2><ul><li>Hierarchical Bayesian Normal Model:
$$ y_1, &mldr;, y_n \vert \theta_1, &mldr;, \theta_n, \mu \overset{ind}{\sim} N(\theta_i, \sigma^2)$$
$$ \theta_1, &mldr;, \theta_n \vert \mu \overset{iid}{\sim} N(\mu, \tau^2)$$
$$ p(\mu) \propto 1$$
where $\sigma^2$ and $\tau^2$ are assumed to be known.</li><li>Joint posterior density
$$ \begin{aligned}
p(\theta, \mu \vert y) &\propto e^{-\frac{1}{2\sigma^2} \sum_{i=1}^n (y_i -\theta_i)^2} e^{-\frac{1}{2 \tau^2} \sum_{i=1}^n (\theta_i -\mu)^2} \
&\sim N (\frac{\frac{1}{\sigma^2} y_i + \frac{1}{\tau^2} \mu}{\frac{1}{\sigma^2} + \frac{1}{\tau^2}}, [\frac{1}{\sigma^2} +\frac{1}{\tau^2}]^{-1})
\end{aligned}$$</li><li>Marginal posterior density of $\mu$
$$ p(\mu \vert y) = \int \cdots \int p(\theta_1, &mldr;, \theta_n, \mu \vert y) d \theta_1 &mldr; d \theta_n$$</li><li>Conditional posterior density of $\mu$
$$ p(\mu \vert \theta, y) \sim (\bar \theta, \frac{\tau^2}{n})$$</li></ul><h1 id=monte-carlo-integration>Monte Carlo Integration</h1><h2 id=numerical-integration>Numerical Integration</h2><ul><li>Bayesian computation<ul><li>Posterior distribution, $p(\theta \vert y)$</li><li>Posterior preedictive distribution, $p(\tilde y \vert y)$</li></ul></li><li>For complicated or unusual models or in high dimensions, more elaborate algorithms are required to approximate the posterior distruution.</li><li>Numberical integration methods<ul><li>Deterministic methos: Newton-Cotes quadrature, Romberg integration, Gaussian quadrature, etc.</li><li>Not appropriate for high-dimensional Bayesian problems.</li><li>Simulation methods : Monte Carlo integration</li></ul></li></ul><h2 id=monte-carlo-integration-1>Monte Carlo Integration</h2><ul><li><p>Monte Carlo integration is a simple and powerful method for computing the value of complex integrals using probabilistic thecniques.</p></li><li><p>Suppose that $\theta$ has a posterior density $p(\theta \vert y)$ and we are interested in learning about a particular function of the parameters $h(\theta)$. THe posterior mean of $h(\theta)$ is given by:
$$ E[h(\theta) \vert y] = \int h(\theta) p(\theta \vert y) d \theta$$</p></li><li><p>Suppose we are able to simulate an independent sample $\theta_1, &mldr;, \theta_n$ from the posterior density. The Monte Carlo estimate at the posterior mean is given by the sample mean:
$$ \bar h_{MC} = \frac{1}{n} \sum_{i=1}^n h(\theta_i)$$</p></li><li><p>The associated simulation standard error of this estimate is estimated by
$$ SE(\bar h_{MC}) = \sqrt{\frac{\sum_{i=1}^n (h(\theta_i) - \bar h_{MC})^2}{n(n-1)}}$$</p></li><li><p>We consider the problem of approximating the value of integrals such as $\int_a^b g(x) dx$</p></li><li><p>Suppose that $X_i \overset{iid}{\sim} Unif[a, b]$. Then the density of $X_i$ is $f(x) = \frac{1}{b - a} I_{[a, b]} (x)$.
$$\begin{aligned}
\int_a^b g(x) & = (b-a) \int_a^b g(x) f(x) dx \
& = (b-a) E[g(X)]\
\approx \frac{b -a}{n} \sum_{i=1}^n g(X_i)
\end{aligned}$$
for sufficiently large n.</p></li></ul><h1 id=rejection-sampling>Rejection Sampling</h1><h2 id=rejection-sampling-1>Rejection Sampling</h2><ul><li>Rejection sampling is one of the most useful methods for simulating draws from a variety of distributions.</li><li>In many situations, the posterior doest not have a familiar form and we need to use an alternative algorithm for producing a simulated sample.</li><li>Suppose we wish to produce an independent sample from a posterior density $p(\theta \vert y)$ where the normalizing constant may not be known.</li><li>The first step is to find another probability density $g(\theta)$ such that:<ul><li>It is easy to simulate draws from $g$.</li><li>The density $g$ resembles the posterior density of interest $p$ in terms of location and spread.</li><li>For all $\theta$ and a constant $M$, $p(\theta \vert y) \le M g(\theta)$</li></ul></li><li>Suppose we are able to find a density $g$ with these properties. THen, one obtains draws from $p$ using the following accept/reject algorithm:<ol><li>Indepdently simulate $\theta^*$ from $g$, and a uniform random variable $U$ on the unit interval.</li><li>If $U \le \frac{p(\theta^* \vert y)}{M g(\theta^<em>)}$, then accept $\theta^</em>$ accept $\theta^<em>$ as a draw from the density p; otherwise reject $\theta^</em>$.</li><li>Continue steps 1 and 2 of the algorithm until one has collected a sufficient number of &ldquo;accepted&rdquo; $\theta^*$</li></ol></li></ul><h2 id=remarks>Remarks</h2><ul><li>The main task in designing a rejection sampling algorithm is finding a suitable proposal density $g$ and constant value $M$.</li><li>The probability of accepting a candidate draw is given by $p(\theta \vert y) / (M g(\theta))$.</li><li>One can monitor the algorithm by computing the proportion of draws of $g$ that are accepted; an efficent rejction sampling algorithm has a high acceptance rate.</li><li>The more closely the shape of $g$ resembles that of $p$, the more efficient the sampling will be.</li><li>A good approximate density $g$ should be roughly proportional to $p$.</li><li>When $g$ is not nearly proportional to $p$, the bound $M$ must be set so large that almost all draws obtained in step 1 will be rejected in step 2.</li></ul><h1 id=importance-sampling>Importance Sampling</h1><h2 id=importance-sampling-1>Importance sampling</h2><ul><li><p>Importance sampling is a method that is used for computing expectations using a random sample drawn from an approximation to the target distribution.</p></li><li><p>Suppose we are interested in $E[h(\theta) \vert y]$, but we cannot generate random draws of $\theta$ from $p(\theta \vert y)$ and thus cannot evaluate the integral by a simple average of simulated values.</p></li><li><p>Idea of importance sampling: draw the sample from a proposal distribution and re-weight the integral using importance weights so that the correct distribution is targeted.</p></li><li><p>The normalizing constant of the posterior density $p(\theta \vert y)$ will be unknown, so the posterior mean of the function $h(\theta)$ will be given by the ratio of integrals
$$E[h(\theta) \vert y] = \frac{\int h(\theta) p(\theta) p(y \vert \theta) d \theta}{\int p(\theta) p(y \vert \theta) d \theta}$$</p></li><li><p>In the case where we are not able to generate a sample directly from $p$, suppose instread that we can construct a probability density $g$ that we can simulate and that approximates the posterior density $p$. We rewrite the posterior means as
$$ \begin{aligned}
E[h(\theta) \vert y] = \frac{\int h(\theta) w(\theta) g(\theta) d\theta}{\int w(\theta) g(\theta) d \theta}
\end{aligned}$$
where $w(\theta) = p(\theta) p(y \vert \theta ) /g(\theta)$ is the weight function.</p></li><li><p>If $\theta_1, &mldr;, \theta_n$ are a simulated sample from the approximation density $g$, then the importance sampling estimate of the posterior mean is
$$ \bar h_{IS} = \frac{\sum_{i=1}^n h(\theta_i) w(\theta_i)}{\sum_{i=1}^n w(\theta_i)}$$
This is called an importance sampling estimate because we are sampling values of $\theta$ that are important in computing the integrals in the numerator and denominator.</p></li><li><p>The simulation standard error of an importance sampling estimate is estimated by
$$ SE(\hat h_{IS}) = \frac{\sqrt{\sum_{i=1}^n ((h(\theta_i) - \bar h_{IS}) w(\theta_i))^2}}{\sum_{i=1}^n w(\theta_i)}$$</p></li></ul><h2 id=remarks-1>Remarks</h2><ul><li>The main issue in designing a good importance sampling estimate is finding a suitable sampling density $g$.</li><li>This density should be of a familiar functional form so simulated draws are avaiable. The density should mimic the posterior density $p$ and have relatively flat and thicker tails so that the weight function $w(\theta)$ is bounded from above.</li><li>One can monitor the choice of $g$ by inspecting the values of the simulated weights $w(\theta_i)$. If there are no unusually large weights, then it is likely that the weight function is bounded and the importance sampler is providing a suitable estimate.</li></ul><h1 id=markov-chain-monte-carlo>Markov Chain Monte Carlo</h1><h2 id=markov-chains>Markov Chains</h2><ul><li>Consider a sequnce of random variables {$X^{(t)}$}, t= 0,1, &mldr; , where each $X^{(t)}$ may equal one of a finite or countably infinite number of possible values, called states.</li><li>The notation $X^{(t)} = j$ indicates that the process is in state j at time t.</li></ul></div><script src=/js/wikilink.js></script><div><script src=https://utteranc.es/client.js repo=minuk-dev/minuk-dev.github.io issue-term=pathname theme=github-dark crossorigin=anonymous async></script></div></main><footer class=footer><div class=footer-left></div><div class=footer-right><ul class=social><li><a href=/about>About</a></li><li><a href=https://github.com/minuk-dev>Github</a></li></ul></div></footer>