<!doctype html><html lang=ko-kr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title></title><style>html body{font-family:raleway,sans-serif;background-color:#fff}:root{--accent:#00a3d2;--border-width:5px}</style><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Raleway"><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css integrity=sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN crossorigin=anonymous><link rel=stylesheet href=/css/main.css><link rel=stylesheet href=/css/copy-btn.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script src=/js/copy-btn.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script>$(document).on("click",function(){$(".collapse").collapse("hide")})</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-98056974-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-98056974-1")</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><meta name=google-site-verification content="g_3tJyj-KkW-_wKx7Ij5GimHV1nKPZXetCz8ydbBAfA"></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><a class="navbar-brand visible-xs" href=#></a><button class=navbar-toggle data-target=.navbar-collapse data-toggle=collapse>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span></button></div><div class="collapse navbar-collapse"><ul class="nav navbar-nav"><li><a href=/>Home</a></li><li><a href=/wiki/>Wiki</a></li><li><a href=/posts/>Posts</a></li><li><a href=/about/>About</a></li></ul></div></div></nav><main><div class=navigator style=display:flex><div style=display:flex><a href=/wiki/><button class="btn btn-link"><i class="fa fa-arrow-left"></i>&nbsp;Front Page</button></a></div></div><div><h2></h2><a href=https://github.com/minuk-dev/minuk-dev.github.io/blame/master/content/wiki/lectures/compiler.md><h5>created : Mon, 01 Jan 0001 00:00:00 +0000</h5><h5>modified : Mon, 01 Jan 0001 00:00:00 +0000</h5></a></div><aside class=navbar id=nav-toc style=text-align:left><nav id=TableOfContents><ul><li><ul><li><a href=#--->&mdash;</a></li></ul></li><li><a href=#parent---lectures>layout : wiki
title : 컴파일러 수업 정리
summary : 2022-1 컴파일러 수업 정리
date : 2022-03-25 22:26:53 +0900
lastmod : 2022-06-15 15:53:46 +0900
tags : [lecture]
draft : false
parent : lectures</a></li></ul><ul><li><a href=#the-move-to-higher-level-languages>The Move to Higher-Level Languages</a></li><li><a href=#using-high-level-languages-is-a-free-lunch>Using High-Level Languages is a Free Lunch?</a></li><li><a href=#the-major-role-of-language-processors>The Major Role of Language Processors</a></li><li><a href=#two-representative-strategies>Two Representative Strategies</a></li><li><a href=#common-language-processing-systems>Common Language-Processing Systems</a></li><li><a href=#requirements-for-designing-good-compilers>Requirements for Designing Good Compilers</a></li><li><a href=#structure-of-modern-compilers>Structure of Modern Compilers</a><ul><li><a href=#lexical-analyzer-scanner>Lexical Analyzer (Scanner)</a></li><li><a href=#syntax-analyzer-parser>Syntax Analyzer (Parser)</a></li><li><a href=#semantic-analyzer>Semantic Analyzer</a></li><li><a href=#intermediate-code-generator>Intermediate Code Generator</a></li><li><a href=#code-optimization-optional>Code Optimization (Optional)</a></li><li><a href=#code-generator>Code Generator</a></li></ul></li></ul><ul><li><a href=#part1-specification-of-tokens>Part1. Specification of Tokens</a><ul><li><a href=#overview>Overview</a></li><li><a href=#definition-tokens>Definition: Tokens</a></li><li><a href=#definition-lexemes>Definition: Lexemes</a></li><li><a href=#class-of-tokens>Class of Tokens</a></li><li><a href=#lexical-anlysis-does>Lexical Anlysis does</a></li><li><a href=#for-the-specifcation-of-tokens>For the specifcation of tokens</a></li><li><a href=#definition-alphabet-string-and-language>Definition: Alphabet, String, and Language</a></li><li><a href=#operations-on-strings>Operations on Strings</a></li><li><a href=#operations-on-languages>Operations on Languages</a></li><li><a href=#regurlar-expressions>Regurlar Expressions</a></li><li><a href=#rules-for-regular-expressions>Rules for Regular Expressions</a></li><li><a href=#to-recognize-tokens>To Recognize Tokens</a></li><li><a href=#summary>Summary</a></li></ul></li><li><a href=#part-2-recognition-of-tokens>Part 2. Recognition of Tokens</a><ul><li><a href=#finite-automata>Finite Automata</a></li><li><a href=#deterministic-vs-non-deterministic>Deterministic vs. Non-deterministic</a></li><li><a href=#procedures-for-implementing-lexical-analyzers>Procedures for Implementing Lexical Analyzers</a></li><li><a href=#regular-expressions-to-nfas>Regular Expressions to NFAs</a></li><li><a href=#nfas-to-dfas>NFAs to DFAs</a></li><li><a href=#summary-1>Summary</a></li></ul></li></ul><ul><li><a href=#part-1-context-free-grammars-cfg>Part 1. Context-Free Grammars (CFG)</a><ul><li><a href=#syntax-analyzer>Syntax Analyzer</a></li><li><a href=#why-dont-we-use-regular-expressions>Why don&rsquo;t we use regular expressions?</a></li><li><a href=#context-free-grammars-cfg>Context-Free Grammars (CFG)</a></li><li><a href=#derivations>Derivations</a></li><li><a href=#token-validation-test>Token Validation Test</a></li></ul></li></ul><ul><li><a href=#part-1-scope-checking>Part 1: Scope Checking</a><ul><li><a href=#the-most-closely-nested-scope-rule>The Most-Closely Nested Scope Rule</a></li><li><a href=#implementation-of-scope-checking>Implementation of Scope Checking</a></li><li><a href=#summary-scope-checking>Summary: Scope Checking</a></li></ul></li><li><a href=#part-2-type-checking>Part 2: Type Checking</a><ul><li><a href=#type-type-system-and-type-checking>Type, Type System, and Type Checking</a></li><li><a href=#two-kinds-of-languages>Two Kinds of Languages</a></li><li><a href=#how-types-are-usedchecked-in-practice>How Types are Used/Checked in Practice?</a></li><li><a href=#rules-of-inference>Rules of Inference</a></li><li><a href=#problem-1-free-variables>Problem #1: Free Variables</a></li><li><a href=#how-types-are-usedchecked-in-practice-1>How Types are Used/Checked in Practice?</a></li><li><a href=#summary-type-checking>Summary: Type checking</a></li></ul></li></ul><ul><li><a href=#tree-address-code-tac>Tree Address Code (TAC)</a><ul><li><a href=#intermediate-code-generator-1>Intermediate Code Generator</a></li><li><a href=#ast-abstract-syntax-tree>AST: Abstract Syntax Tree</a></li><li><a href=#tactree-address-code>TAC:Tree Address Code</a></li><li><a href=#types-of-tacvariable-assignment>Types of TAC:Variable Assignment</a></li><li><a href=#how-to-represent-tac-quadruples>How to Represent TAC: Quadruples</a></li><li><a href=#ast-to-tac>AST to TAC</a></li><li><a href=#summary-intermediate-code-generator>Summary: Intermediate Code Generator</a></li></ul></li></ul><ul><li><a href=#local-optimization>Local Optimization</a><ul><li><a href=#intermediate-code-optimizer>Intermediate Code Optimizer</a></li><li><a href=#basic-blocks>Basic Blocks</a></li><li><a href=#control-flow-graphs>Control Flow Graphs</a></li><li><a href=#types-of-intermediate-code-optimizations>Types of Intermediate Code Optimizations</a></li><li><a href=#local-optimizations>Local Optimizations</a></li><li><a href=#implementation-of-local-optimizations>Implementation of Local Optimizations</a></li><li><a href=#summary-intermediate-code-optimizer>Summary: Intermediate Code Optimizer</a></li></ul></li><li><a href=#global-optimization>Global Optimization</a><ul><li><a href=#global-optimizations>Global Optimizations</a></li><li><a href=#global-dead-code-elimination>Global Dead Code Elimination</a></li><li><a href=#global-copy-propataion--common-subexpressions-eliminzation>Global Copy Propataion / Common Subexpressions Eliminzation</a></li><li><a href=#summary-global-optimizations>Summary: Global Optimizations</a></li></ul></li></ul><ul><li><a href=#part-1-runtiem-environment>Part 1: Runtiem Environment</a><ul><li><a href=#code-generator-1>Code Generator</a></li><li><a href=#runtime-environment>Runtime Environment</a></li><li><a href=#object-representations>Object Representations</a></li><li><a href=#function-representations>Function Representations</a></li><li><a href=#memory-layout>Memory Layout</a></li><li><a href=#summary-runtime-envornment>Summary: Runtime Envornment</a></li></ul></li><li><a href=#part-2-code-generation>Part 2: Code Generation</a><ul><li><a href=#assembly-languages>Assembly Languages</a></li><li><a href=#mips-assembly>MIPS assembly</a></li><li><a href=#better-register-allocation>Better Register Allocation</a></li></ul></li></ul></nav></aside><div align=start class=content data-spy=scroll data-offset=20 data-target=#nav-toc style=position:relative><h3 id=--->&mdash;</h3><h2 id=parent---lectures>layout : wiki
title : 컴파일러 수업 정리
summary : 2022-1 컴파일러 수업 정리
date : 2022-03-25 22:26:53 +0900
lastmod : 2022-06-15 15:53:46 +0900
tags : [lecture]
draft : false
parent : lectures</h2><h1 id=introduction>Introduction</h1><ul><li>Programming Languages<ul><li>Notations for describing computations to people and to machines</li><li>All the software running on all the computers was written in some programming languages</li><li>Before a program can be run, it first must be translated into a form in which it can be executed by a computer</li></ul></li><li>Compilers<ul><li>The software systems that do this translation</li></ul></li></ul><h2 id=the-move-to-higher-level-languages>The Move to Higher-Level Languages</h2><ul><li>The evolution of programming languages<ul><li>Machine Languages : Machine instructions(= the patterns of 0&rsquo;s and 1&rsquo;s)</li><li>Assembly Langues : <code>ADD t1,t2</code></li><li>Higher-Level Lanagues : C, C++, Java, Python</li></ul></li></ul><h2 id=using-high-level-languages-is-a-free-lunch>Using High-Level Languages is a Free Lunch?</h2><ul><li>No<ul><li>How can a program written in some high-level language be executed by computer?<ul><li>Language translation (additional process) is required</li></ul></li></ul></li></ul><h2 id=the-major-role-of-language-processors>The Major Role of Language Processors</h2><ul><li>Language Translation<ul><li>Translates source code (e.g., C, C++, Java, Python, &mldr;) into semantically-equivalent target code (e.g., Assembly / Machin languages)</li></ul></li><li>Error Detection<ul><li>Detects and reports any errors in the soruce program duting the translation process</li></ul></li></ul><h2 id=two-representative-strategies>Two Representative Strategies</h2><table><thead><tr><th></th><th>Compilation</th><th>Interpretation</th></tr></thead><tbody><tr><td>What to translate</td><td>An entire source program</td><td>One statement of a source program</td></tr><tr><td>When to translate</td><td>Once before the program runs</td><td>Every time when the statement is executed</td></tr><tr><td>Translation Result</td><td>A target program (equivalent to the source program)</td><td>Target code (equivalent to the statement)</td></tr><tr><td>Examples</td><td>C, C++</td><td>Javascript</td></tr></tbody></table><ul><li><p>Compilation:</p><ul><li>Pros: Runs faster, Optimized, No dependencies</li><li>Cons: Additional Step, Incompatibility issue, Hard to Debug</li></ul></li><li><p>Interpretation:</p><ul><li>Pros: Execution Control, Cross Platform, Easier to Debug</li><li>Cons: Slower, Not Optimized, Dependencies file rquired</li></ul></li><li><p>Hybrid Compilers:</p><ul><li>Combine compilation and interpretation (e.g., Java, Python)</li></ul></li></ul><h2 id=common-language-processing-systems>Common Language-Processing Systems</h2><ul><li>source program -> Preprocessor - (modified source program) -> Compiler - (target assembly program) -> Assembler - (relocatable machine code) -> Linker/Loader -> target machine code</li></ul><h2 id=requirements-for-designing-good-compilers>Requirements for Designing Good Compilers</h2><ul><li>Correctness (Mandatory)</li><li>Performance Improvment (Optional)</li><li>Reasonable Compilation Time (Optional)</li></ul><h2 id=structure-of-modern-compilers>Structure of Modern Compilers</h2><ul><li>Modern compilers preserve the outlines of the FORTRAN I compiler<ul><li>The first compiler, in the last 1950s</li><li>source program -> Lexical Analyzer -> Syntax Analyzer -> Semantice Analyer -> Intermeidate Code Generator -> Code Optimizer -> Code Generator</li></ul></li></ul><h3 id=lexical-analyzer-scanner>Lexical Analyzer (Scanner)</h3><ul><li>Devides the stream of characters into meaningful sequences and produces a set of tokens</li><li>Input : Character stream</li><li>Output : Token</li></ul><h3 id=syntax-analyzer-parser>Syntax Analyzer (Parser)</h3><ul><li>Creates a tree-like intermediate representation (e.g., syntax tree) that depicts the grammatical structure of the token stream</li><li>Input : Token</li><li>Output : Syntax Tree</li></ul><h3 id=semantic-analyzer>Semantic Analyzer</h3><ul><li>Checks the source program for semantic consistency with the language definition (e.g., type checking/conversion)</li><li>Input : Syntax tree</li><li>Output : Syntax tree</li></ul><h3 id=intermediate-code-generator>Intermediate Code Generator</h3><ul><li>Constructs intermediate representations<ul><li>They should be easy to produce and easy to translate into a targe tmachine code</li></ul></li><li>Input: Syntax tree</li><li>Output : Intermediate representation</li></ul><h3 id=code-optimization-optional>Code Optimization (Optional)</h3><ul><li>Attempts to improve the intermediate code so that better target code will result (e.g., better code = faster or shorter code)</li><li>Input : Intermediate representation</li><li>Output : Intermediate representation</li></ul><h3 id=code-generator>Code Generator</h3><ul><li>Maps an intermediate representation of the source into the target language</li><li>Input : Intermeidate representation</li><li>Output : Target-machine code</li></ul><h1 id=lexical-analysis>Lexical Analysis</h1><h2 id=part1-specification-of-tokens>Part1. Specification of Tokens</h2><h3 id=overview>Overview</h3><ul><li>What does a lexical analzyer do?<ul><li>Reading the input characters of a source program</li><li>Grouping the characters into meaningful sequences, called lexemes</li><li>Producing a sequence of tokens</li><li>Storing the token information into a symbol table</li><li>Sending the tokens to a syntax analzyer</li></ul></li></ul><h3 id=definition-tokens>Definition: Tokens</h3><ul><li>A token is a syntactic category<ul><li>Examples:<ul><li>In English: noun, verb, adjective, &mldr;</li><li>In a programming language: identifer, number, operator, &mldr;</li></ul></li><li>Tokens are structured as a pair consisting of a token name and an optional token value<ul><li>Example: an identifier A<ul><li>Its token name is &ldquo;identifier&rdquo; and its token value is &ldquo;A&rdquo;</li></ul></li></ul></li></ul></li></ul><h3 id=definition-lexemes>Definition: Lexemes</h3><ul><li>A lexeme is a sequence of characters that mathces the patterns ofr a token<ul><li>Pattern: a set of rules that defines a token</li><li>Examples<table><thead><tr><th>Token (token name)</th><th>Lexeme</th></tr></thead><tbody><tr><td>IDENTIFIER( or simple ID)</td><td>pi, score, i, j, k</td></tr><tr><td>Number</td><td>0, 3.14, &mldr;</td></tr><tr><td>IF</td><td>if</td></tr><tr><td>COMMA</td><td>,</td></tr><tr><td>LPAREN</td><td>(</td></tr><tr><td>LITERAL</td><td>&ldquo;Hello World&rdquo;</td></tr><tr><td>COMPARISION</td><td>&lt;, >, &lt;=, ==, &mldr;</td></tr></tbody></table></li></ul></li></ul><h3 id=class-of-tokens>Class of Tokens</h3><ul><li>Keyword:<ul><li>e.g., IF for if, ELSE for ele, FLOAT for float, CHAR for char</li></ul></li><li>Operators:<ul><li>e.g., ADD for +, COMPARISON for &lt;, >, == , and ..</li></ul></li><li>Identifiers:<ul><li>e.g., ID for all kinds of identifiers</li></ul></li><li>Constants:<ul><li>e.g., NUMBER for any numeric constant, INTEGER, REAL, LITERAL</li></ul></li><li>Punctuation Symbols:<ul><li>e.g., LPAREN for (, COMMA for ,</li></ul></li><li>Whitespace<ul><li>e.g., a non-empty sequence of blanks, newlines, and tabs<ul><li>Lexical analzyers usually discard uninteresting tokens that don&rsquo;t contribute to parsing (e.g., whitespace, comment)</li></ul></li></ul></li></ul><h3 id=lexical-anlysis-does>Lexical Anlysis does</h3><ol><li>Partitioning input strings into sub-strings (lexemes)</li><li>Identifying the token of each lexeme</li></ol><h3 id=for-the-specifcation-of-tokens>For the specifcation of tokens</h3><ul><li>Why do we use &ldquo;reuglar languages&rdquo;?<ul><li>Simple, but powerful enough to describe the pattern of tokens</li></ul></li><li>The coverage of formal languages<ul><li>Reuglar Lnague &lt; Context-Free Language &lt; Context-Sensitive Language &lt; Recursively Enumerable Language</li></ul></li></ul><h3 id=definition-alphabet-string-and-language>Definition: Alphabet, String, and Language</h3><ul><li><p>An alphabet $\Sigma$ is nay finite set of symbols</p><ul><li>Letter = $\Sigma^L$ = {a, b, c, &mldr;, z, A, B, C, &mldr; , Z}</li><li>Digit = $\Sigma^D$ = {0, 1, &mldr;, 9}</li></ul></li><li><p>A string s over alaphabet $\Sigma$ is a finite sequence of symbols drawn from the alphabet:</p><ul><li>If $\Sigma = { 0 }$, s = 0, 00, 000, or, &mldr;</li><li>If $\Sigma = { a, b }$, s = a, b, aa, ab, &mldr;</li></ul></li><li><p>A language L is any set of strings over some fixed alphabet $\Sigma$</p></li><li><p>If $\Sigma = { a, b}$, $L_1 = {a, ab, ba, aba }$ and $L_2 = { a, b, aa, ab, ba, bb, aa, &mldr; }$
- $L_1$ is a finite language (the number of strings in the language is finite)
- $L_2$ is an infinite language (the number of strings in the language is infinite)</p></li></ul><h3 id=operations-on-strings>Operations on Strings</h3><ul><li>$s$: A string (A finite sequence of symbols over alphabet $\Sigma$)</li><li>$\vert s \vert$ : The length of s (the number of occurences of symbols in $s$)</li><li>$s_1 s_2$ : Concatenation of $s_1$ and $s_2$</li><li>$\epsilon$ : An empty string</li><li>$s^i$ : Exponentiation of $s$ (concatenation of $s$ i-times)</li></ul><h3 id=operations-on-languages>Operations on Languages</h3><ul><li>$L$ : A language (A set of strings over alphabet $\Sigma$)</li><li>$L_1 \cup L_2$: Union of $L_1$ and $L_2$ {s $\vert$ s in $L_1$ or s is in $L_2$}</li><li>$L_1L_2$ : Concatenation of $L_1$ and $L_2$ {$s_1s_2$ $\vert$ $s_1$ is in $L_1$ and $s_2$ is in $L_2$}</li><li>$L^i$ : Concatenation of $L$ i-times</li><li>$L^*$ : Kleene closure of $L$ (Concatenation of $L$ zero or more times)</li><li>$L^+$ : Positive closure of $L$ (Concatenation of $L$ one or more times)</li></ul><h3 id=regurlar-expressions>Regurlar Expressions</h3><ul><li>A notation of describing regular languages<ul><li>Each regular expression $r$ describes a regular language $L(r)$</li></ul></li><li>Basic regular expressions</li></ul><table><thead><tr><th>Regular expression</th><th>Expressed regular language</th></tr></thead><tbody><tr><td>$\epsilon$</td><td>$L(\epsilon) = { \epsilon }$</td></tr><tr><td>$a$</td><td>$L(a) = { a }$, where $a$ is a symbol in alphabet $\Sigma$</td></tr><tr><td>$r_1 \vert r_2$</td><td>$L(r_1) \cup L(r_2)$, where $r_1$ and $r_2$ are regular expressions</td></tr><tr><td>$r_1 r_2$</td><td>$L(r_1r_2) = L(r_1) L(r_2) = { s_1 s_2 \vert s_1 \in L(r_1) \text{ and } s_2 \in L(r_2)}$</td></tr><tr><td>$r^*$</td><td>$L(r^*) = \Cup_{i \ge 0} L(r^i)$</td></tr></tbody></table><ul><li>A An expression is a regular expression<ul><li>If and only if it can be described by using the basic reuglar expressions only</li></ul></li></ul><h3 id=rules-for-regular-expressions>Rules for Regular Expressions</h3><ul><li>Precedence : exponentiation (*, +) > concatenation > union ($\vert$)<ul><li>$(r_1) \vert (r_2)^* (r_3)) = r_1 \vert r_2^* r_3$</li></ul></li><li>Equivalence:<ul><li>$r_1 = r_2, \text{ if } L(r_1 = L(r_2))$</li></ul></li><li>Algebraic laws<table><thead><tr><th>Operations</th><th>Laws</th></tr></thead><tbody><tr><td>$\vert$(union)</td><td>- Communitative :$r_1 \vert r_2 = r_2 \vert r_1$, - Associative : $r_1 \vert (r_2 \vert r_3) = (r_1 \vert r_2) \vert r_3$ \</td></tr><tr><td>concatenation</td><td>- Associative : $r_1 (r_2r_3) = (r_1 r_2)r_3$, - Concatenation distributes over $\vert$ : $r_1(r_2 \vert r_3) = r_1 r_2 \vert r_1 r_3$</td></tr><tr><td>$\epsilon$</td><td>- The identity ofr concatenation : $r-1 \epsilon = \epsilon r_1 = r_1$</td></tr><tr><td>$a^*$</td><td>- Idempotent: $a^{**} = a^{*}$</td></tr></tbody></table></li></ul><h4 id=examples-of-specifying-tokens>Examples of Specifying Tokens</h4><ul><li>$Keyword = if \vert else \vert for \vert \cdots$</li><li>$Comparision = &lt; \vert > \vert &lt;= \vert >= \vert \cdots$</li><li>$Whitespace = \text{ } \vert \text{\t} \vert \text{\n} \vert \cdots$</li><li>$Digit = [0-9] = 0 \vert 1 \vert \cdots \vert 9$</li><li>$Integer = Digit^*$</li><li>$Identifier = {letter_ } ({letter_ } \vert {digit})^*$</li><li>$optionalFraction = .Integer \vert \epsilon$</li><li>$optionalExpoent = (E (+ \vert - \vert \epsilon) Integer) \vert \epsilon$</li><li>$Float = \text{Integer optionalFraction optionalExponent}$</li></ul><h3 id=to-recognize-tokens>To Recognize Tokens</h3><ol><li>Merge the regular expression of tokens
$Merged = Keyword \vert Identifier \vert Comparison \vert Float \vert Whitespace \vert \cdots$</li><li>When an input stream $a_1 a_2 a_3 \cdots a_n$ is given,</li></ol><pre tabindex=0><code>mIdx = 0;
for i &lt;= i &lt;= n
  if a_1 a_2 ... a_n \in L(Merged), mIdx = i;
end
partition and classify a_1 a_2 ... a_{mIdx}
</code></pre><ol start=3><li>Do the step 2 for the remaning input stream</li></ol><h3 id=summary>Summary</h3><ul><li>What does a lexical analyzer do?<ul><li>token</li><li>getNextToken</li></ul></li><li>How to specify the pattern for tokens? Regular Languages</li><li>How to recognize the tokens from input streams? Finite Automata</li></ul><h2 id=part-2-recognition-of-tokens>Part 2. Recognition of Tokens</h2><h3 id=finite-automata>Finite Automata</h3><ul><li>The implementation ofr recognizing tokens<ul><li>It accepts or rejects inputs based on the patterns specified in the form of regular expressions</li></ul></li><li>A finite automata $M = {Q, \Sigma, \delta, q_0, F}$<ul><li>A finite set of sets $Q= {q_0, q_1, &mldr;, q_i}$</li><li>An input alphabet $\Sigma$: a finite set of input symbols</li><li>A start state $q_0$</li><li>A set of accepting (or final) states $F$ which is a subset of $Q$</li><li>A set of state transition functions $\delta$</li></ul></li><li>A finite automata can be expressed in the form of graphs, a transition graph</li><li>A finite automata can be also expressed in the form of table, a transition table</li></ul><h3 id=deterministic-vs-non-deterministic>Deterministic vs. Non-deterministic</h3><ul><li>Deterministic Finite Automata (DFA):<ul><li>(Exactly or at most) one transition for each state and for each input symbol</li><li>No $\epsilon$-moves</li></ul></li><li>Non-deterministic Finite Automata (NFA):<ul><li>Multiple transitions for each state and for each input symbol are allowed</li><li>$\epsilon$-moves are allowed</li></ul></li><li>DFAs and NFAs can recognize the same set of regular languages</li><li>DFA:<ul><li>One deterministic path for a single input</li><li>Accepted if and only if the path is from the start state one of the final states</li></ul></li><li>NFA:<ul><li>Multiple possible paths for a single input</li><li>Accepted if and only if any path among hte possible paths is from the start state to one of the final states</li></ul></li></ul><table><thead><tr><th></th><th>DFA</th><th>NFA</th></tr></thead><tbody><tr><td>transitions</td><td>All transitions are deterministic</td><td>Some transitions could be non-deterministic</td></tr><tr><td>$\epsilon$-move</td><td>x</td><td>o</td></tr><tr><td># paths for a given input</td><td>Only one</td><td>One or more</td></tr><tr><td>Accepting condition</td><td>For a given input, its path must end in one of accepting states</td><td>For a given input, there must be at least one path ending in one of accepting states</td></tr><tr><td>Pros</td><td>Fast to execute</td><td>Simple to represent (easy to make/understand)</td></tr><tr><td>Cons</td><td>Complex ->space problem (exponentially larger than NFA)</td><td>Slow -> performance problem (several paths)</td></tr></tbody></table><h3 id=procedures-for-implementing-lexical-analyzers>Procedures for Implementing Lexical Analyzers</h3><ul><li>Lexical Specifications -> Regular Expressions -> NFA -> DFA(in the form of a transition table)</li></ul><h3 id=regular-expressions-to-nfas>Regular Expressions to NFAs</h3><ul><li>McNaughton-Yamada-Thompson algorithm<ul><li>This works recursively by splitting an expression into its constituent subexpressions</li></ul></li></ul><h3 id=nfas-to-dfas>NFAs to DFAs</h3><ul><li>Subset (powerset) construction algorithm:<ul><li>Basic idea: Grouping a set of NFA states reachable after seeing some input strings</li></ul></li><li>Definitions:<ul><li>$\epsilon$-closure($q^N$) : A set of NFA states reachable from NFA state $q^N$ with only $\epsilon$-moves ($q^N$ is also included)</li><li>$\epsilon$-closure(T) : A set of NFA states reachable from some NFA state in a set $T = { q_i, &mldr; }$ with only $\epsilon$ - moves</li></ul></li></ul><h3 id=summary-1>Summary</h3><ul><li>What does a lexical analyzer do?<ul><li>Reading the input characters of a source program</li><li>Grouping the characters into meaningful sequences, called lexemes</li><li>Producing a sequence of tokens</li><li>Storing the token information into a symbol table</li><li>Sending the tokens to a syntax analzyer</li></ul></li></ul><h1 id=syntax-analysis-parser>Syntax Analysis (Parser)</h1><h2 id=part-1-context-free-grammars-cfg>Part 1. Context-Free Grammars (CFG)</h2><h3 id=syntax-analyzer>Syntax Analyzer</h3><ol><li>Decides whether a given set of tokens is valid or not</li></ol><ul><li>Parse tree:<ul><li>It shows how the start symbol of a grammar derives a string in the language</li><li>Given a context-free grammar, a parse tree is a tree is a tree with the following properties:<ul><li>The root is labeled by the start symbol</li><li>Each leaf is labeled by a terminal or by $\epsilon$</li><li>Each interior node is labeled by a non-terminal</li><li>If $A$ is the non-terminal labeling some interior node and $X_1, &mldr;, X_n$ are the labels of the children of that node from left to right, then there must be a production $A \rightarrow X_1 X_2 \cdots X_n$</li></ul></li></ul></li></ul><ol start=2><li>Creates a tree-like intermediate representation (e.g., parse tree) that depicts the grammatical structure of the token stream</li></ol><h3 id=why-dont-we-use-regular-expressions>Why don&rsquo;t we use regular expressions?</h3><ul><li>It is not sufficient to depict the syntax of programming languages</li></ul><h3 id=context-free-grammars-cfg>Context-Free Grammars (CFG)</h3><ul><li>A notation for describing context free languages</li><li>A CFG consists of:<ul><li>Terminals: the basic symbols (usually, token name = terminal)<ul><li>Terminals can not be replaced</li></ul></li><li>Non-terminals: syntactic variables:<ul><li>Non-terminals can be replaced by other non-terminals or terminals</li></ul></li><li>A start symbol: one non-terminal (usually, the non-terminals of the first rule)</li><li>Productions(->) : a rule for replacement</li></ul></li><li>It is good at expressing the recursive structure of a program</li><li>In our programming languages, recursive structures are very frequently observed.</li></ul><h3 id=derivations>Derivations</h3><ul><li>A derivation ($\Rightarrow$) is a sequence of replacements.<ul><li>$\Rightarrow^*$ : Do derivations zero or more times</li></ul></li><li>A rule for derivations:<ul><li>Leftmost($\Rightarrow_{lm}$) : replace the left-most non-terminal first</li><li>Rightmost($\Rightarrow_{rm}$) : replace the right-most non-terminal first</li></ul></li></ul><h3 id=token-validation-test>Token Validation Test</h3><ul><li>Definition : A sentinel form of a CFG G<ul><li>$\alpha$ is a sentinel form of G, if $A \Rightarrow^* \alpha$, where A is the start symbol of G<ul><li>If $A \Rightarrow_{lm}^* \alpha$ or $A \Rightarrow_{rm}^* \alpha$, $\alpha$ is a (left or right) sentinel form of G</li></ul></li></ul></li><li>Definition: A sentence of a CFG G:<ul><li>$\alpha$ is a sentence form of G,</li><li>If $\alpha$ is a sentinel form of a CFG G which consists of terminals only</li></ul></li><li>Definition: A language of a CFG G:<ul><li>$L(G)$ is a language of a CFG G</li><li>$L(G) = { \alpha \vert \alpha \text{ is a sentence of G}}$</li></ul></li><li>If an input string (e.g., a token set) is in $L(G)$, we can say that it is valid in G</li></ul><ol><li>Decides whether a given set of tokens is valid or not</li></ol><ul><li>Q. How to specify the rule for deciding valid token set?</li><li>A. Make a context free grammar G based on the rule of a programming language</li><li>Q. How to distinguish between valid and invalid token sets?</li><li>A. Check whether the given token set can be derived from the context free grammar G</li></ul><ol start=2><li>Creates a tree-like intermediate representation (e.g., parse tree) that depicts the grammatical structure of the token stream</li></ol><h1 id=semantic-analyzer-1>Semantic Analyzer</h1><ul><li>Check many kinds of semantic grammars:<ul><li>Semantic grammars can be different depending on the programming language</li></ul></li><li>Common semantic grammars:<ul><li>Scope checking:<ul><li>All variables must be declared before their use (globally or locally)</li><li>All variables must be declared only once (locally)</li><li>All functions must be declared only once (globally)</li></ul></li><li>Type checking:<ul><li>All variables must be used with the right type of constant or variables</li><li>All functions must be used with the right number and type of arguments</li></ul></li></ul></li></ul><h2 id=part-1-scope-checking>Part 1: Scope Checking</h2><ul><li>The scope of an identifier is the portion of a program in which the identifier can be accessed:<ul><li>Scope matches identifier declarations with uses</li><li>The same identifier may refer to different things in different scopes</li></ul></li><li>Two type of scope:<ul><li>Static scope (used in most programming languages):<ul><li>Scope depends on the physical structure of program text:<ul><li>e.g., {}, ()</li></ul></li></ul></li><li>Dynamic scope (use in LISP, SNOBOL):<ul><li>Scope depends on execution of the program:<ul><li>e.g., the most currently declared identifier is used</li></ul></li></ul></li></ul></li><li>In most programming langues, the scope of identifiers are determined with:<ul><li>Function declarations</li><li>Class declarations</li><li>Variable declarations</li><li>Formal parameters</li></ul></li></ul><h3 id=the-most-closely-nested-scope-rule>The Most-Closely Nested Scope Rule</h3><ul><li>An identifier is matched with the identifier declared in the most-closely nested scope:<ul><li>The identifier should be declared before it is used</li></ul></li></ul><h3 id=implementation-of-scope-checking>Implementation of Scope Checking</h3><ul><li>While travelling AST:<ul><li>Update the symbol table with the scope information</li><li>But such simple solution can occur problems:<ul><li>Problem 1: Ambiguity</li><li>Problem 2: Inefficiency</li></ul></li><li>Construct a symbol table for each scope, describing a nesting structure</li><li>Update the symbol table with information about what identifiers are in the scope</li><li>When an identifier is used, find the identifier in the current symbol table:<ul><li>If not exist, moves to its parent table and find the identifier in the table</li><li>Repeat this process until the identifier is detected or their is no more parent table</li></ul></li></ul></li><li>How to support function call/class name used before declarations?:<ul><li>Solution: Multi-pass scope checking:<ul><li>Pass 1: Gather information about all function/class names</li><li>Pass 2: Do scope checking</li></ul></li></ul></li></ul><hr><h3 id=summary-scope-checking>Summary: Scope Checking</h3><ul><li>The scope of an identifier is the portion of a program in which the identifier can be accessed:<ul><li>Scope mathces identifier declarations with uses</li><li>The same identifier may refer to different things in different scopes</li></ul></li><li>For scope check, we use the most-closely nested scope rule:<ul><li>Construct a symbol table for each scope, describing a nesting structure</li><li>Udpate the symbol table with information about what identifiers are in the scope</li><li>When an identifier is used, find the identifier in the current symbol table</li></ul></li><li>Semantic analysis usually requires multiple (probably more than two) passes:<ul><li>To allow to use function calls/ class names before declaration</li></ul></li></ul><h2 id=part-2-type-checking>Part 2: Type Checking</h2><h3 id=type-type-system-and-type-checking>Type, Type System, and Type Checking</h3><ul><li>What is a type (data type)?:<ul><li>An attribute of data which teslls compilers how programmers intend to use the data</li></ul></li><li>What is a type system?:<ul><li>A set of rules that assign specific types to the various constructs of a computer program</li></ul></li><li>What is a type checking?:<ul><li>Ensuring that the types of the operands match the type expected by the operator</li></ul></li><li>Why do we need type checking?:<ul><li>We cannot distinguish expressions without type in the assembly languagee level</li><li>We should do the type checking with higher-level representations</li></ul></li></ul><h3 id=two-kinds-of-languages>Two Kinds of Languages</h3><ul><li>Statically-typed languages:<ul><li>The type of a variable is determined/known at compile time</li><li>Type checking is performed during compile-time (before run-time)</li><li>Advantage: better run-time performance + easy-to-understand/easy-to-find type-related bugs(due to strict rules)</li></ul></li><li>Dynamically-typed languages:<ul><li>The type of a variable is assocatied with run-time values</li><li>Type checking is performed on the fly, during execution</li><li>Advnatage: higher flexibility + rapid prototyping support</li></ul></li></ul><h3 id=how-types-are-usedchecked-in-practice>How Types are Used/Checked in Practice?</h3><ul><li>In statically-typed lanagues:<ul><li>Programmers declare types for all identifiers statically:<ul><li>Types are ssociated with specific keywords</li></ul></li></ul></li><li>Compilers:<ul><li>Infer the type of each expression from the types of its components</li><li>Confirm that the types of expressions matches what is expected</li></ul></li></ul><h3 id=rules-of-inference>Rules of Inference</h3><ul><li>Inference rules usually have the form of &ldquo;if-then&rsquo; statements:<ul><li>If hypothesis is true, then conclusion is true</li></ul></li><li>Type checking computes via reasoning</li><li>Notations for rules of inferences:<ul><li>x: T = x has type T</li><li>$\frac{Hypothesises}{Conclusions}$ = if-then statement, &ldquo;if Hypothesises are true, Conclustions are true&rdquo;</li><li>$\vdash$ = &ldquo;we can infer&rdquo;</li><li>Examples:<ul><li>For an expression A && B:<ul><li>If we can infer that A has type bool and B has type bool, then we can infer that A && B has type bool:<ul><li>$$\frac{\text{We can infer that A has type bool and B has type bool}}{\text{We can infer that A && B has type bool}} \ \frac{\vdash \text{A has type bool } \vdash \text{B has type bool}}{\vdash \text{A && has type bool}} \ \frac{\vdash A:bool \vdash B:bool}{\vdash \text{A && B}: bool}$$</li></ul></li></ul></li></ul></li></ul></li></ul><h3 id=problem-1-free-variables>Problem #1: Free Variables</h3><ul><li>Free variables?:<ul><li>A variable is free in an expression if its type if not defined/declared within the expression</li></ul></li></ul><h4 id=solution-adding-scope-information>Solution: Adding Scope Information</h4><ul><li>Scoping information can give types for free variables</li><li>$$S \vdash e:T$$</li><li>We can infer that an exression e has type T in scope S:<ul><li>Types are now proven relative to the scope the expression are in</li></ul></li><li>So far, we&rsquo;ve defined inference rules for expressions</li><li>Q. How to check whether statements are semantically well-formed or not?</li></ul><h4 id=solution-defining-well-formedness-rules>Solution: Defining Well-Formedness Rules</h4><ul><li>Extend our proof system (rules of inferences) to statements</li><li>$$S \vdash WF(stmt)$$</li><li>We can infer that a statement stmt is semantically well-formed in scope S</li></ul><h3 id=how-types-are-usedchecked-in-practice-1>How Types are Used/Checked in Practice?</h3><ul><li>In statically-typed language, programmers declare types for all identifiers:<ul><li>Types are associated with specific keywords</li></ul></li><li>Compilers:<ul><li>Infer the type of each expression from the types of its components</li><li>Confirm that the types of expressions matches what is expected</li><li>Especially, by using the rules of inference + scope information + well-formedness rules</li></ul></li><li>How to use the inference rules for type checking?:<ul><li>First, before doing type-checking</li><li>For each statement:<ul><li>Do type checking for any subexpressions it contains</li><li>Do type checking for child statements</li><li>Check the overall well-formedness</li></ul></li></ul></li></ul><hr><h3 id=summary-type-checking>Summary: Type checking</h3><ul><li>Ensuring that the types of the operands match the type expected by the operator</li><li>In statically-typed lanauges:<ul><li>Programmers declare tyeps for all identifiers statically:<ul><li>Types are associated with specific keywords</li></ul></li></ul></li><li>Compilers:<ul><li>Infer the type of each expression from the types of its components</li><li>Confirm that the types of expressions matches what is expected</li><li>Especially, by using the rules of inference + scope information + well-formedness rules</li></ul></li><li>How to use the inference rules for type checking?:<ul><li>Before doing type checking, do scope-checking, first</li></ul></li><li>For each statement:<ul><li>Do type-checking for any sub-expressions it contains</li><li>Do type-checking for child statements</li><li>Check the overall well-formedness</li></ul></li></ul><h1 id=compilers-intermediate-code-generator>Compilers: Intermediate Code Generator</h1><h2 id=tree-address-code-tac>Tree Address Code (TAC)</h2><h3 id=intermediate-code-generator-1>Intermediate Code Generator</h3><ul><li>Translates a high-level intermediate representation (e.g., parse trees or AST) into a low-level intermediate representation (e.g., three address code)</li><li>Why do we use an intermediate representation?:<ul><li>Easy-to-understand/optimize:<ul><li>Doing optimizations on an intermediate representation is much easier and clearer than that on a machine-level code</li><li>A machine code has many constraints that inhabit optimizations</li></ul></li><li>Easy-to-be-translated:<ul><li>Compared to a high-level code, it looks much more like a machine-level code</li><li>Therefore, we can translate an intermediate representation to a machine-level code with low cost</li></ul></li></ul></li><li>How to design a good intermediate representation?:<ul><li>&ldquo;Often a single compiler has multiple intermediate representations&rdquo;</li><li>Different intermediate representations have different information/characteristics which can be used for optimizations</li><li>In GCC,:<ul><li>Source Code -> AST -> Generic -> High GIMPLE -> SSA -> Low GIMPLE -> RTL -> Machine Code</li></ul></li></ul></li></ul><h3 id=ast-abstract-syntax-tree>AST: Abstract Syntax Tree</h3><ul><li>Abstract syntax trees look like parse trees, but without some parsing details</li><li>We can eliminate the following nodes in parse trees:<ul><li>Single-successor nodes</li><li>Symbols for describing syntactic details</li><li>Non-terminals with an operator and arguments as their child nodes</li></ul></li><li>AST can be constructed by using semantic actions</li></ul><h3 id=tactree-address-code>TAC:Tree Address Code</h3><ul><li>A high-level assembly where each operation has at most three operands:<ul><li>A linearized representation of AST</li></ul></li><li>Components of TAC:<ul><li>Operands (= addresses)</li><li>Operators (= instructions)</li></ul></li></ul><h3 id=types-of-tacvariable-assignment>Types of TAC:Variable Assignment</h3><ul><li>Copy operation:<ul><li>Explicit or temporary variable = any kind of operand</li></ul></li><li>Binary operation:<ul><li>Explicit or temporary variable = any kind of operand binary operator any kind of operand:<ul><li>Binary operators:<ul><li>Arithmetic operatiors: +, -, *, /, &mldr;</li><li>Boolean operators: &&, ||, &mldr;</li><li>Comparision operators: ==, != &mldr;</li></ul></li></ul></li></ul></li><li>Unary operation:<ul><li>Explicit or temporary variable = unary operator any kind of operand:<ul><li>Unary operators: -, !</li></ul></li></ul></li><li>Unconditional jump with label</li><li>Conditional branch</li><li>Call procedures</li><li>Array operations</li><li>Return statements</li></ul><h3 id=how-to-represent-tac-quadruples>How to Represent TAC: Quadruples</h3><ul><li>Quadruples have four fields (op, arg1, arg2, results) and they are stored in a linked list</li></ul><h3 id=ast-to-tac>AST to TAC</h3><ul><li>When constructing AST, we define TAC construction rules for each node:<ul><li>TAC construction rules:</li><li>Operation Node<ul><li>Create a new quadruple with op</li><li>arg1 = the computation resul of its left child</li><li>arg2 = the computation result of its right child</li><li>result = a new temporary variable t_i</li><li>Store the qudruple to the end of the linked list</li><li>Return its value</li></ul></li></ul></li><li>While traveling AST, construct TAC based on the rules</li><li>TAC construction rules for whlie:<ul><li>Create and store a neq quadruple with op = label, arg1 = a new label L_i</li><li>Create a new quadruple with op = if not</li><li>arg1 = the computation result of tis left child (compute condition)</li><li>arg2 = another new lavel L_j</li><li>Store the quadruple</li><li>Compute the right child (compute the while statements&rsquo;block)</li><li>Create and store a new quadruple with op = goto, arg1 = L_i</li><li>Create and store a new quadruple with op = label, arg1 = L_j</li></ul></li></ul><hr><h3 id=summary-intermediate-code-generator>Summary: Intermediate Code Generator</h3><ul><li>Translates a high-level intermediate representation (e.g., parse tree or AST into a low-level intermediate representation (e.g., three address code))</li></ul><h1 id=code-optimization>Code Optimization</h1><h2 id=local-optimization>Local Optimization</h2><h3 id=intermediate-code-optimizer>Intermediate Code Optimizer</h3><ul><li>Improves the code generated by the intermeidate code generator:<ul><li>For optimizing the run-time performance, memory usage, and power consumption of the program, the preserving the semantics of the original program</li></ul></li><li>Why do we need optimization?:<ul><li>Intermediate code is generated without considering optimization</li><li>Programmers write a poor code frequently</li></ul></li><li>Optimizations can be also performed with machine-level code:<ul><li>To improve performance based on the characteristics of specific machines</li></ul></li><li>Intermediate code optimizations try to improve performance more generally (independently of machines)</li></ul><h3 id=basic-blocks>Basic Blocks</h3><ul><li>A basic block is a maximal sequence of consecutive three adderes instructions:<ul><li>A program can only enter the basic block through the first instruction in the block</li><li>The program leves the block without halting or branching at the last instruction in the block</li></ul></li></ul><h3 id=control-flow-graphs>Control Flow Graphs</h3><ul><li>A control flow graph is a graph of the basic blocks:<ul><li>Edges indicates which blocks can fllow which other blocks</li></ul></li></ul><h3 id=types-of-intermediate-code-optimizations>Types of Intermediate Code Optimizations</h3><ul><li>An optimization is &ldquo;local&rdquo;:<ul><li>If it works on just a single basic block</li></ul></li><li>An optimization in &ldquo;global&rdquo;:<ul><li>If it works on an entire control-flow graph</li></ul></li></ul><h3 id=local-optimizations>Local Optimizations</h3><ul><li>Typical local optimization techniques:<ul><li>Common sub-expressions elimination</li><li>Copy propagation</li><li>Dead code elimination</li><li>Arithmetic simplification</li><li>Constant folding</li></ul></li></ul><h3 id=implementation-of-local-optimizations>Implementation of Local Optimizations</h3><ul><li><p>Available expression analysis:</p><ul><li>For common sub-expressions elimination & copy propagation:<ul><li>An expression is called avilable if variabels in the expression hold an up-to-date value</li></ul></li><li>Determine for each point in a program the set of available expressions:<ul><li>Initially, no expressions are available</li><li>Whenever we check a statement a = opeartaion:<ul><li>Any expression holding a is invalidated!</li><li>The new expression a = operation becomes avaiable</li></ul></li></ul></li></ul></li><li><p>Common sub-expressions elimination with available expressions:</p><ul><li>Let&rsquo;s suppose that we currently check an expressio nb = operation1 and an expression a= operation1 is in the set of available expression:<ul><li>The right-hand sides of two expressions are same</li><li>Then, replace the right-hand side of the current expression (b = operation1) by the left-hand side of the corresponding available expression( a= operation1)</li></ul></li></ul></li><li><p>Copy propagation with available expressions:</p><ul><li>let&rsquo;s suppose that we currently check an expression c= operation with b and an expression b = a or b = constant number is in the set of available expressions</li><li>Then, replace b in the right-hand side of the current expression (c = oepration with b) by a (the right-hand side of the corresponding avaiable expression) (b=a)</li></ul></li><li><p>Live variable analysis:</p><ul><li>For dead code elimination:<ul><li>A variable is called a live variable if ti holds a value that will be needed in the future</li></ul></li><li>Two know whether a variable will be used in the future or not, checks the statements in a basic block in a reverse order:<ul><li>Initially, some small set of variables are known to be live</li><li>Just before executing the statement a = &mldr; b &mldr;:<ul><li>a is not alive because its value will be newly overritten</li><li>b is alive because it will be used</li></ul></li></ul></li></ul></li><li><p>Dead code elimination with live variables:</p><ul><li>Let&rsquo;s suppose that we currently check an expression b = operation1 and b is not a live variable after this assignment</li><li>Then, eliminate the assignment statement</li></ul></li></ul><hr><h3 id=summary-intermediate-code-optimizer>Summary: Intermediate Code Optimizer</h3><ul><li>Improve the code generated by the intermediate code generator:<ul><li>For optimizing the run-time performance, memory usage, and power consumption of the program, but preserving the semantics of the original program</li><li>Types of optimizations:<ul><li>Local optimizations</li><li>Global optimizations</li></ul></li><li>Typical local optimization techniques:<ul><li>Common sub-expressions elimination:<ul><li>through avaiable expression analysis</li></ul></li><li>Copy propagation:<ul><li>through available expression analysis</li></ul></li><li>Dead code elimination:<ul><li>through live variable analysis</li></ul></li><li>Arithmetic simplification</li><li>Constant folding</li></ul></li></ul></li></ul><h2 id=global-optimization>Global Optimization</h2><h3 id=global-optimizations>Global Optimizations</h3><ul><li>Work on a control-flow graph as a whole:<ul><li>Many of the local optimization techniques can be applied globally:<ul><li>Global dead code elimination</li><li>Global copy propagation / common sub-expression elimination</li></ul></li></ul></li></ul><h3 id=global-dead-code-elimination>Global Dead Code Elimination</h3><h3 id=global-copy-propataion--common-subexpressions-eliminzation>Global Copy Propataion / Common Subexpressions Eliminzation</h3><ul><li>Key idea: computer available expressions globally</li></ul><h3 id=summary-global-optimizations>Summary: Global Optimizations</h3><ul><li>Work on a control-flow graph as a whole:<ul><li>Many of local optimization techniques can be applied globally:<ul><li>Global copy/constant propagation</li><li>Global dead code elimination</li></ul></li><li>Some optimizations are possible in global analysis that aren&rsquo;t possible locally:<ul><li>e.g. code motion: moving code from basic block into another to avoid unneccessary computations</li></ul></li></ul></li></ul><h1 id=compilers-code-generation>Compilers: Code Generation</h1><h2 id=part-1-runtiem-environment>Part 1: Runtiem Environment</h2><h3 id=code-generator-1>Code Generator</h3><ul><li>Translates an intermediate representation (e.g., three address code) into a machine-level code (e.g., assembly code)</li></ul><h3 id=runtime-environment>Runtime Environment</h3><ul><li>A set of data structures used at runtime to support high-level structures</li><li>This environment deals with a variety of issues:<ul><li>What do objects look like in memory?:<ul><li>The representation of the objects in memory space</li></ul></li><li>What do functions look like in memory?:<ul><li>The linkages between functions</li><li>The machanisms passing parameters</li></ul></li><li>Where in memory should objects and functions be placed?:<ul><li>The layout and allocation of memory space for the ojbects and functions</li></ul></li></ul></li></ul><h3 id=object-representations>Object Representations</h3><ul><li><p>Data alignment:</p><ul><li>Compilers determine how objects are arranged & accessed in computer memory:<ul><li>Objects are N-bytes aligned in memory space:<ul><li>N-byte alignment: the start memory address of objects is a multiple of N bytes</li><li>N can be different depending on the type of objects</li></ul></li></ul></li></ul></li><li><p>Representing arrays:</p><ul><li>In different programming languages, arrays are differently represented in memory space</li></ul></li><li><p>For an array A[n],:</p><ul><li>C-style arrays: each element A[i] is stored consecutively in memory space(aligned based on its base type)</li><li>Java-style arrays: each element A[i] is stored consecutiely in memory space + size information is prepended</li></ul></li><li><p>Representing multi-dimensional arrays:</p><ul><li>Often represned as an array arrays</li></ul></li></ul><h3 id=function-representations>Function Representations</h3><ul><li>Two main questions related with function representations:<ul><li>How to represent the relationship between functions?</li><li>How to keep the information needed to manage functions?</li></ul></li></ul><h4 id=activations>Activations</h4><ul><li>An invocation of a funciton F is called an activation of F:<ul><li>The lifetime of an activation of F is until all the statements in F is executed</li><li>F can invoke another function Q:<ul><li>Then, the lifetime of an activation of F included the execution of all the statements in Q</li></ul></li><li>The relationship between function activations can be depicted as a tree, called an activation tree</li></ul></li></ul><h4 id=activation-records>Activation Records</h4><ul><li>The information needed to manage an activation of function F:<ul><li>Input parameters:<ul><li>This is supplied by the caller of F</li></ul></li><li>Space for F&rsquo;s return value:<ul><li>This is needed by the caller of F and filled when F is completed</li></ul></li><li>Control link: a pointer to the previous activation record (the caller of F)</li><li>Machine status prior to calling F(e.g., return address, contents of registers)</li><li>F&rsquo;s local, temporary variables</li></ul></li></ul><hr><ul><li>Two main questions related with function representations:<ul><li>How to represent the relationship between functions?: Use a stack</li><li>How to keep the information needed to manage functions?: Store an activation record</li></ul></li></ul><h3 id=memory-layout>Memory Layout</h3><ul><li>Compilers determine how code and data are stored in memory:<ul><li>Assumption: a program uses contiguous memory space</li><li>Global variables:<ul><li>All references to global variable to the same object</li><li>Global variables cannot be stored in an activation record</li><li>Instead, global variables are assigned a fixed address</li><li>Statically allocated</li></ul></li><li>Activation records:<ul><li>Managed in a stack</li><li>The stack grows from high addresses to low addresses</li></ul></li><li>Dynamically-allocated data:<ul><li>Dynamically-allocated data is managed in a heap</li><li>The heap grows from low addresses to high addresses</li><li>&ldquo;To avoid the overlap between the stack and heap&rdquo;</li></ul></li></ul></li></ul><hr><h3 id=summary-runtime-envornment>Summary: Runtime Envornment</h3><ul><li><p>A set of data structures used at runtime to support high-level structures</p></li><li><p>This environment dealts with a variety of issues:</p><ul><li>What do objects look like in memory?:<ul><li>&ldquo;Data structure alignment, array representations..&rdquo;</li></ul></li><li>What do functions look like in memory?:<ul><li>&ldquo;Keep activation records functions in a tack&rdquo;</li></ul></li><li>Where in memory should objects and functions be placed?:<ul><li>Determine memory layout for code and data&rdquo;</li></ul></li></ul></li><li><p>Compiler dtermines, at compile-time, the memory layout of code and data, and generates code that correctly accesses the location of target data</p></li></ul><h2 id=part-2-code-generation>Part 2: Code Generation</h2><h3 id=assembly-languages>Assembly Languages</h3><ul><li>Any low-level(machine-level) programming language:<ul><li>Each assembly language is specific to a particular computer architecture</li></ul></li></ul><h3 id=mips-assembly>MIPS assembly</h3><ul><li>Chracteristics:<ul><li>Only load and store instructions access memory</li><li>All other instructions use registers as operands</li><li>Registers:<ul><li>Can be accessed quickly</li><li>Can have computations performed on them</li><li>But, exist in small quantity</li></ul></li></ul></li><li>Basic instructions:<ul><li>lw reg1 offset(reg2) : reg1 = reg2[offset]</li><li>sw reg1 offset(reg2) : reg2[offset] = reg1</li><li>add reg1 reg2 reg3: reg1 = reg2 + reg3:<ul><li>sub, mul, div</li></ul></li><li>seq reg1 reg2 reg3: reg1 = reg2 == reg3:<ul><li>sne, sgt, sge, slt, sle</li></ul></li><li>li reg1 immediate: reg1 = immediate</li><li>addi reg1 reg2 immediate: reg1 = reg2 + immediate<ul><li>subi, muli, divi</li></ul></li><li>seqi reg1 reg2 immediate: reg1 = reg2 == immediate<ul><li>snei, sgti, sgei, slti, slei</li></ul></li></ul></li></ul><h3 id=better-register-allocation>Better Register Allocation</h3><ul><li><p>Goal: reduce the number of memory reads and writes with limited resources:</p><ul><li>By using no more registers than those available</li><li>By holding as many variables as possible in registers</li></ul></li><li><p>Register Allocation with Live Variable Analysis:</p><ul><li>Step 1: Do live variable analysis globally</li><li>Step 2: Construct RIG(Register Interference Graph):<ul><li>Node: each variable</li><li>Edge: they are alive simultaneously at some point in the program</li></ul></li></ul></li></ul><h4 id=graph-coloring--register-allocation>Graph Coloring = Register ALlocation</h4><ul><li><p>Color = register</p></li><li><p>If the RIG is K-colorable, then there is a register allocationthat uses no more than K registers</p></li><li><p>The graph coloring problem is known as an NP-hard problem:</p><ul><li>No efficient algorithms are known</li><li>The conmputation complexity of the most efficient on: O(2^n n), where n is the number of variables</li><li>Key idea:<ul><li>Eliminate a node T which has neighbors fewer tha nK</li><li>If the remaining RIG is K-colorable, then the RIg with T is also K-colorable</li></ul></li><li>Implementation:<ul><li>Step 1: Pick a node T with fewer than K neighbors</li><li>Step 2: Eliminate T from the RIG and put it on a stack</li><li>Step 3: Repeat the stp 1-2 until there is no node in the RIG</li><li>Step 4: Pick the node in the top-of-stack</li><li>Step 5: Assign a color different from those already assigned to colored neighbors</li><li>Step 6: Repeat the step 4-5 until the RIG is completely restored</li></ul></li></ul></li></ul></div><script src=/js/wikilink.js></script><div><script src=https://utteranc.es/client.js repo=minuk-dev/minuk-dev.github.io issue-term=pathname theme=github-dark crossorigin=anonymous async></script></div></main><footer class=footer><div class=footer-left></div><div class=footer-right><ul class=social><li><a href=/about>About</a></li><li><a href=https://github.com/minuk-dev>Github</a></li></ul></div></footer>